<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>[论文阅读02]Intelligent Network Slicing for V2X Services Towards 5G</title>
    <link href="/2020/08/11/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB01-Intelligent-Network-Slicing-for-V2X-Services-Towards-5G/"/>
    <url>/2020/08/11/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB01-Intelligent-Network-Slicing-for-V2X-Services-Towards-5G/</url>
    
    <content type="html"><![CDATA[<blockquote><p>论文出处：<a href="https://arxiv.org/abs/1910.01516"><em>《Intelligent Network Slicing for V2X Services Towards 5G》</em></a><em>（IEEE Network 2019，中科院SCI期刊分区 Q1，来自北邮的研究团队）</em></p></blockquote><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>摘要里大概谈了这么几点：</p><ul><li>得益于目前广泛部署的LTE基础设施，5G网络对于推进车联网发展起了至关重要的作用（即NR-V2X）</li><li>现有LTE网络满足不了严格而动态的V2X业务，克服这一问题的有效方法是网络切片。通过切片可以实现在通用物理基础架构之上构建多个逻辑网络，以支持不同的V2X业务</li><li>为缓解5G网络切片日益复杂的问题，作者探讨了AI技术在自动化网络操作的使用。具体来说，这篇文章里提出了一个V2X业务的智能网络切片架构，在这一架构里将网络功能（VNF）和多维网络资源（3C资源，即computing + communication + caching）虚拟化，并分配到不同的网络切片。为智能地实现最优的切片，包括移动数据收集和ML算法设计在内的几个关键问题将被探讨，以。然后，我们开发了一个仿真plAI能为实现网络的自动化操作发挥其优势，充分调度各项资源实现各类V2X业务的QoS需求</li><li>设计了一个仿真，来说明作者提出的智能网络切片的有效性（我比较好奇这个，综述看多了还是想落回到怎么开展仿真）</li></ul><h2 id="1-INTRODUCTION"><a href="#1-INTRODUCTION" class="headerlink" title="1. INTRODUCTION"></a>1. INTRODUCTION</h2><p>伴随自动驾驶技术和车辆数量的增长，未来会催生出大量的V2X业务，这些业务大体上可以分为：safety releted和entertainment related（感觉可以理解为车联网背景下的URLLC和eMBB业务）。这些业务在数据速率、可靠性以及时延存在等性能上着多样性的需求。例如，自动驾驶需要低于10毫秒的通信延迟，并且通信可靠性为99.999%；相比之下，娱乐业务主要关注高数据速率，对通信延迟和可靠性的容忍度较高。尽管LTE为支持V2X业务已经做了一定工作（比如3gpp在R14标准化工作里引入了LTE-V2X的概念），但LTE网络本质上还是个“one size fits all”（中文好像翻译成一刀切？）的架构，不能很好满足多样化的V2X业务要求。</p><p>5G比4G引入了很多的新技术，除了在空口上的NOMA、Massive MIMO等，网络的软件化、虚拟化对于满足各项V2X业务也是较为关键的技术。</p><ol><li>网络软件化旨在提供高度灵活的端到端通信，SDN和NFV是两项关键的技术。SDN可以提供全局视角的网络信息，以及实现可编程化的网络控制；NFV则使得网络功能和各种资源不再被限制于专用的物理设备内。通过无线网络软件化，移动网络运营商可以依据业务要求定制专用逻辑网络，以更好地保证业务的QoS需求，这种逻辑网络即网络切片。网络切片横跨接入网和核心网中功能的灵活配置。显然，网络切片的优势十分适用于车联网环境，满足不同V2X业务的差异化需求。</li><li>另外，由于车联网的高复杂性和网络拓扑的高动态性，对车联网网络环境的精准感知和快速决策响应变得非常具有挑战。与传统系统／网络设计方法相比（？这个具体是啥有人懂吗），AI技术可以自动提取网络动态并根据历史观察做出决策，无需对系统需要专业和完善的知识，可应用于无线网络的不同领域。因此，有必要利用AI技术来促进无线网络的部署和管理，实现5G网络的自动化和自进化。</li></ol><p>基于以上，为V2X业务提供高度自动的网络切片非常有前景。利用人工智能技术，我们可以智能地提取具有复杂结构和内部关联的网络切片的高层模式，而这些通过传统的基于模型的方法很难实现。因此，这篇文章的研究范围是弥补网络软件化和网络智能化之间的差距，对基于AI的5G网络片架构在车载网络V2X业务中的应用进行了初步研究，主要要回答两个问题：</p><ul><li>如何设计一种灵活的网络切片体系结构，对车辆网络中各种异构资源进行虚拟化，用来实现网络切片?</li><li>如何利用先进的AI方法定制网络切片，同时考虑到车辆网络的具体需求</li></ul><p>（INTRODUCTION看完后还是很虚，这种有关网络架构的综述性文章一般都这样，AI、SDN、VNF、网络切片等比较热门的词都会涉及到，但限于本人的知识范畴，目前还没有找到哪篇文章能把这些繁杂的概念梳理得令人眼前一亮的，接着往下看吧：）</p><h2 id="2-DIVERSE-REQUIREMENTS-OF-V2X-SERVICES"><a href="#2-DIVERSE-REQUIREMENTS-OF-V2X-SERVICES" class="headerlink" title="2. DIVERSE REQUIREMENTS OF V2X SERVICES"></a>2. DIVERSE REQUIREMENTS OF V2X SERVICES</h2><p>V2X根据通信对象不同，主要包括了Vehicle-to-Pedestrian (V2P), Vehicle-to-Vehicle (V2V), Vehicle-to-Infrastructure (V2I) 和Vehicle-to-Network (V2N)四种通信模式，如图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/xiangli-bjtu/Image-hosting-site/img/v2-497bb425f6cfb0cc27d6138e2dc001ef_b.jpeg" alt="img"></p><p>这篇文章的作者把车联网所支持的业务分为了以下3类，并且给出了各自QoS的对比：</p><p><img src="https://cdn.jsdelivr.net/gh/xiangli-bjtu/Image-hosting-site/img/v2-2a9e01603d8619d4cf3f4cf45706ef9f_b.jpeg" alt="img"></p><blockquote><p>(不过有一点，这篇文章里单独把自动驾驶和交通安全拆开来看是出于啥考虑？自动驾驶所涉及的不应该都和安全相关吗？看了看别的论文会有这样分的：以车辆自动驾驶为核心的交通安全类应用，和非安全应用；后者又可分为以用户体验为核心的信息服务类应用，和以协同为核心的交通效率类应用，感觉这个逻辑上来讲是不是更通点？） * 交通安全类应用：主要与车辆行驶过程中的智能化决策相关，这类应用中的大部分将能够在车辆之间发送和接收数据，而不需要它们与远程云服务器进行连接。这种通信有效地将公路上的每辆车变成其他车辆传感器的延伸，为高速公路环境中提供最佳信息； * 信息服务类应用：是蜂窝移动通信业务面向新的车辆终端的延伸，包括车载视频、车载AR/VR、车载视频通话、车载智慧家庭、路径导航等; * 交通效率类应用：构建智慧城市的重要环节，智能地监控交通运行状况，实现智能的道路监控，缓解交通环境拥堵以期提高交通效率，达到车、路、环境之间的大协同。</p></blockquote><p>不管哪一种划分的角度，面向V2X服务的智能网络切片主体上就是先划出3个大的网络切片吧？至于在每个逻辑网络内又怎么细分呢这应该是后续考虑的事情。</p><h2 id="3-INTELLIGENT-NETWORK-SLICING-ARCHITECTURE-FOR-V2X-SERVICES"><a href="#3-INTELLIGENT-NETWORK-SLICING-ARCHITECTURE-FOR-V2X-SERVICES" class="headerlink" title="3. INTELLIGENT NETWORK SLICING ARCHITECTURE FOR V2X SERVICES"></a>3. INTELLIGENT NETWORK SLICING ARCHITECTURE FOR V2X SERVICES</h2><p>这一章讨论如何设计一种具有高灵活性的智能网络切片结构。</p><p>首先，为了提供集中式的网络切片控制，提出了一种基于SDN技术的车辆网络云架构。在这种集中式的架构上，我们可以方便地构建出V2X业务的智能网络切片。在这样的体系结构能发挥两个优点：</p><ol><li>通过使用NFV，不同种类的资源是从专用的网络基础设施虚拟化，然后网络切片可以定义为一个合适的收集资源，从而进一步增加灵活性。</li><li>另一方面，在考虑车辆特性的同时，通过采用AI技术有效管理网络切片</li></ol><p>（唔，给我的大概感觉就是，SDN和云计算是用来搭建整体的网络架构，然后NFV的作用是将各项可以调度的资源抽象出来，而怎么结合车联网的特性调度资源则需要借助AI技术的分析，最终实现的目标是为各类QoS要求的V2X业务打造其独有的网络切片）</p><h3 id="A-Cloud-based-Framework-for-Vehicular-Networks"><a href="#A-Cloud-based-Framework-for-Vehicular-Networks" class="headerlink" title="A. Cloud-based Framework for Vehicular Networks"></a>A. Cloud-based Framework for Vehicular Networks</h3><p>这篇论文将基于云的车联网框架中划分两个网络域：边缘云和远端云。</p><p>边缘云显然更为重要，其功能决定了V2X业务的服务质量。服务区域囊括了单个或多个宏蜂窝覆盖区域，由于更加接近终端，可以较好地确保较低的端到端响应时间</p><p>远端云具有强大的处理能力和大量的存储资源，由于边缘云资源的有限性，边缘云会存在无法满V2X业务需求的情况，这时需要向远端云申请资源，但为此需要付出额外的信令开销，并且将付出加大响应时延的代价。</p><p><img src="https://cdn.jsdelivr.net/gh/xiangli-bjtu/Image-hosting-site/img/v2-23a5092389fc98136bef34bc65a73b2e_b.jpeg" alt="img"></p><p>（不过我看有些论文，还有一层车云的概念即构成了3层的车联网架构。未来的车辆本身具有一定的资源可以使用，但考虑到移动中的车辆会使得这层所谓的云结构太不稳定了吧。不过之前看过一个论文提到个场景比较有意思：考虑在一个大型停车场里的环境下，用泊车的资源来承担计算任务。但是这些车辆的异构熟悉、私有属性，怎么允许你使用他们的资源？）</p><h3 id="B-Design-of-Intelligent-Network-Slicing-Architecture"><a href="#B-Design-of-Intelligent-Network-Slicing-Architecture" class="headerlink" title="B. Design of Intelligent Network Slicing Architecture"></a>B. Design of Intelligent Network Slicing Architecture</h3><p>上述的车联网架构，为不同V2X业务的网络切片和基于AI的网络控制奠定了基础。作者把网络切片划分为以下图的四层结构（不过我很好奇这个四层，和上面讲的那个基于云的两层结构逻辑上是怎么个对应，理解得很模糊？）</p><p><img src="https://cdn.jsdelivr.net/gh/xiangli-bjtu/Image-hosting-site/img/v2-67f4f8fd0fe3c87fe89bd67ed6e4aa36_b.jpeg" alt="img"></p><ul><li><strong>Network infrastructure virtualization layer:</strong> </li></ul><p>网络基础设施层，这一层要解决两件事：</p><ol><li>每个网络域中的不同设备的资源都被映射到资源池，这个资源池分为了3个维度的资源：communication, computing and storage三种资源（应该要借助各种底层硬件的虚拟化技术，具体怎么实现的不是很了解）</li></ol><p>\2. VNF池：VNF即虚拟化网络功能，这一层在上述的3C资源池之上。为实现不同的网络功能，不同的VNF单元要使用到数量彼此不同的3C资源。控制层可在VNF集合中选择需要的VNF组合，提供不同V2X服务奠定基础。</p><ul><li><strong>Intelligent control layer：</strong></li></ul><p>控制层主要是配置和管理网络中的切片，具体来说选择合适的VNF来定制专门的网络切片；此外，控制层也负责收集、保存与分析车联网中生成的移动数据，可以利用先进的AI算法分析高级特征。（看来是整个架构里负责智能处理的环节所在）。</p><p>而这一层需要注意的是：由于车联网环境的移动特性和高动态网络拓扑，而且网络规模通常很大。AI算法通常需要更大的移动数据量和更长的处理时间来获得满意的控制的性能。因此直接利用AI算法来处理和优化每个V2X业务QoS要求，很难保障V2X业务的实时性，也会带来相关的处理复杂性。</p><p>为了使智能控制层可以快速且高效地部署和管理网络切片，作者对控制层采用了分级控制的结构：</p><ol><li>Slicing Deployment Controller(SDCon) ：切片配置控制器。位于控制层的底层，在较大的时间尺度上运行，利用ＭＬ算法分析车联网的宏观历史信息和负责网络切片的部署（部署具体是指的啥？）</li><li>Slicing Management Controller (SMCon)：切片管理控制器，负责及时响应和实时管理每个切片中的资源。</li></ol><p>需要注意：AI技术只在切片配置控制器中(SDCon) 中应用（这里估计就是各种论文里提的AI算法具体落地的位置）</p><p>（不太能理解细节：大概就是说要根据两个时间尺度来考量切片的配置，具体每个时间尺度上做些啥，不举例子的话也很难理解）</p><ul><li><strong>Network slice layer:</strong></li></ul><p>网络切片层，正如一开始对V2X业务分类的，存在着3大类别的网络切片。（不过这一层要做啥呢？下面的控制层不是把资源分配做完了吗？这一层就是做个分类？）</p><ul><li><strong>Service customized layer:</strong> </li></ul><p>网络切片定制层，感觉是个面向上层的接口，需要定义各类V2X业务的QoS要求和优先级吧，它们会被作为控制目标来指导下面网络切片的定制工作</p><p>（这一段更多的是讲了网络切片架构的搭建思路，i只能理解个大概的脉络，具体每一项的细节怎么做，和有啥学术上的研究点，还是得去专门找具体的文章结合着来看）</p><h2 id="4-CHALLENGES-AND-SOLUTIONS-IN-INTELLIGENT-NETWORK-SLICING"><a href="#4-CHALLENGES-AND-SOLUTIONS-IN-INTELLIGENT-NETWORK-SLICING" class="headerlink" title="4. CHALLENGES AND SOLUTIONS IN INTELLIGENT NETWORK SLICING"></a>4. CHALLENGES AND SOLUTIONS IN INTELLIGENT NETWORK SLICING</h2><h3 id="A-Mobile-Data-Collection-for-Intelligent-Network-Slicing"><a href="#A-Mobile-Data-Collection-for-Intelligent-Network-Slicing" class="headerlink" title="A. Mobile Data Collection for Intelligent Network Slicing"></a>A. Mobile Data Collection for Intelligent Network Slicing</h3><ul><li>在上面所提的SDCon控制器，需要适当地收集车联网中的数据，并进行适当地预处理，以分析车联网宏观状态的动态变化。直接上图，作者把车联网中需要观测的数据给划归了两类，</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xiangli-bjtu/Image-hosting-site/img/v2-7cce6d5721748f5976e2011c8f526fcb_b.jpeg" alt="img"></p><p>对于这些数据要考虑到它们具有很强的时空关联性 spatio-temporal diversity，这给数据的收集和处理实际上带来了一定的考虑角度：</p><p>一方面：作者把车联网中数据的采集类比于拍照，在不同的地点采集数据会有区别，而同一个地点连续的数据采集，其实会有一定程度上的关联，能反映该地点的平均V2X服务需求情况</p><p><img src="https://cdn.jsdelivr.net/gh/xiangli-bjtu/Image-hosting-site/img/v2-1ad81bb20b98d25c4d023a97287290a1_b.jpeg" alt="img"></p><p>这带来的一点启发是，由于车联网的宏观状态只会在较大的时间维度上变化，因此不需要实时收集数据，每隔一段时间收集数据。实际上，在一个长期的时间尺度上，周期性地收集移动数据是合理避免冗余的方法。</p><h3 id="B-Intelligent-Control-Layer-Powered-by-Deep-Reinforcement-Learning"><a href="#B-Intelligent-Control-Layer-Powered-by-Deep-Reinforcement-Learning" class="headerlink" title="B. Intelligent Control Layer Powered by Deep Reinforcement Learning"></a>B. Intelligent Control Layer Powered by Deep Reinforcement Learning</h3><p>Intelligent Control Layer 中，对于寻找最优的网络切片部署策略，强化学习无疑是最为有效的工具</p><p><img src="https://pic3.zhimg.com/v2-2e9c7f665b445676f385a2b4d98827de_b.jpeg" alt="img"></p><p>此外，作者认为由于时间上的关联，需要结合LSTM网络来考虑。</p><p><img src="https://cdn.jsdelivr.net/gh/xiangli-bjtu/Image-hosting-site/img/v2-f44389565b15944f50cb6c2392ac02ea_b.jpeg" alt="img"></p><p>（读完这一章节两个感悟：</p><ol><li>不知道这种实际的车联网数据去哪里获取，或者有啥仿真可以做到的；</li><li>好好学强化学习吧，感觉车联网里的都是拿这套方法来灌水论文）</li></ol><h2 id="5-SIMULATION-RESULTS-AND-ANALYSIS"><a href="#5-SIMULATION-RESULTS-AND-ANALYSIS" class="headerlink" title="5. SIMULATION RESULTS AND ANALYSIS"></a>5. SIMULATION RESULTS AND ANALYSIS</h2><p>最后是给了一个实验，不赘述了，感兴趣的话去原文看吧。</p>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>V2X</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>David Silver 强化学习教程（5）：免模型的控制</title>
    <link href="/2020/06/08/David%20Silver%20%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%95%99%E7%A8%8B%EF%BC%885%EF%BC%89%EF%BC%9A%E5%85%8D%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%8E%A7%E5%88%B6/"/>
    <url>/2020/06/08/David%20Silver%20%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%95%99%E7%A8%8B%EF%BC%885%EF%BC%89%EF%BC%9A%E5%85%8D%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%8E%A7%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>这一讲的内容主要是在模型未知的条件下如何优化价值函数，这一过程也称作模型无关的控制。</p><p>根据优化控制过程中是否利用已有经验策略来改进我们自身的控制策略，我们可以将这种优化控制分为两类：</p><p><strong>一类是同策略学习（On-policy Learning）</strong>，其基本思想是个体已有一个策略，并且遵循这个策略进行采样，或者说采取一系列该策略下产生的行为，根据这一系列行为得到的奖励，更新状态函数，最后根据该更新的价值函数来优化策略得到较优的策略。这里，要优化的策略就是当前遵循的策略</p><p><strong>另一类是异策略学习（Off-policy Learning）</strong>: 其基本思想是，虽然个体有一个自己的策略，但是个体并不针对这个策略进行采样，而是基于另一个策略进行采样，这另一个策略可以是先前学习到的策略，也可以是人类先验知识等一些较为优化成熟的策略，通过观察基于这类策略的行为，或者说通过对这类策略进行采样，得到这类策略下的各种行为，继而得到一些奖励，然后更新价值函数，即在自己的策略形成的价值函数的基础上观察别的策略产生的行为，以此达到学习的目的。</p><h1 id="On-Policy-Monte-Carlo-Control"><a href="#On-Policy-Monte-Carlo-Control" class="headerlink" title="On-Policy Monte-Carlo Control"></a>On-Policy Monte-Carlo Control</h1><p>在本节中我们使用的主要思想仍然是动态规划的思想。忘记了的不妨去看下第三讲回顾动态规划是如何进行策略迭代的。</p><p>那么这种方法是否适用于模型未知的蒙特卡洛学习呢？答案是否定的，这其中至少存在两个问题。</p><ul><li>一是在模型未知的条件下无法知道当前状态的所有后续状态，进而无法确定在当前状态下采取怎样的行为更合适。（动态规划是需要知道某一状态的所有后续状态及状态间转移概率的）</li><li>另一个问题是，动态规划是采取的贪婪算法来改善策略，将很有可能由于没有足够的采样经验而导致产生一个并不是最优的策略。为了解决这一问题，我们需要引入一个随机机制，以一定的概率选择当前最好的策略，同时给以其它可能的行为一定的几率，这就是之前介绍强化学习时提到的$\epsilon$，数学表达式如下：</li></ul><p>解决了上述两个问题，我们最终看到蒙特卡洛控制的全貌：<strong>使用Ｑ函数进行策略评估，使用$\epsilon$-贪婪探索来改善策略</strong>。该方法最终可以收敛至最优策略。如下图所示：</p><p>在实际求解控制问题时，为了使算法可以收敛，一般ϵϵ会随着算法的迭代过程逐渐减小，并趋于0。这样在迭代前期，我们鼓励探索，而在后期，由于我们有了足够的探索量，开始趋于保守，以贪婪为主，使算法可以稳定收敛。这样我们可以得到一张和动态规划类似的图：</p><h1 id="On-Policy-Temporal-Difference-Control"><a href="#On-Policy-Temporal-Difference-Control" class="headerlink" title="On-Policy Temporal-Difference Control"></a>On-Policy Temporal-Difference Control</h1><p>上一讲提到TD相比MC有很多优点：</p><ol><li>低方差（lower variance）；</li><li>可以在线实时学习；</li><li>可以学习不完整episode等。</li></ol><p>那么是否可以在控制问题上使用TD学习而不是MC学习？答案是肯定的，这就是下文要讲解的<strong>SARSA算法</strong></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>SARSA算法和动态规划法比起来，不需要环境的状态转换模型，和MC法比起来，不需要完整的状态序列，因此比较灵活。在传统的强化学习方法中使用比较广泛。但是也一个传统强化学习方法共有的问题，就是无法求解太复杂的问题，$Q(S,A)$使用一张大表来存储的，如果我们的状态和动作都达到百万乃至千万级，需要在内存里保存的这张大表会超级大，甚至溢出，因此不是很适合解决规模很大的问题。当然，对于不是特别复杂的问题，使用SARSA算还很不错的一种强化学习问题求解方法。</p><h1 id="Off-Policy-Learning"><a href="#Off-Policy-Learning" class="headerlink" title="Off-Policy Learning"></a>Off-Policy Learning</h1>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Reinforcement Learning</tag>
      
      <tag>AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>David Silver 强化学习教程（4）：免模型的预测</title>
    <link href="/2020/06/02/David%20Silver%20%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%95%99%E7%A8%8B%EF%BC%884%EF%BC%89%EF%BC%9A%E5%85%8D%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%A2%84%E6%B5%8B/"/>
    <url>/2020/06/02/David%20Silver%20%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%95%99%E7%A8%8B%EF%BC%884%EF%BC%89%EF%BC%9A%E5%85%8D%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%A2%84%E6%B5%8B/</url>
    
    <content type="html"><![CDATA[<p>上一讲介绍了在掌握MDP细节（即时奖励和转移概率，或者说对环境建立了模型）下如何通过动态规划求解最优价值函数和最优策略。但是由于动态规划法需要在每一次回溯更新某一个状态的价值时，回溯到该状态的所有可能的后续状态。导致对于复杂问题计算量很大。同时很多时候，我们对于环境模型是无法知道的，这时动态规划法根本没法使用。这时候我们如何求解强化学习问题呢？这正是强化学习要解决的问题，通过直接从Agent与环境的交互来得到一个估计的最优价值函数和最优策略。</p><p>本讲的内容聚焦于策略评估也就是model-free prediction；下一讲将利用本讲的主要观念来进行model-free control进而找出最优策略，最大化Agent的奖励。</p><h1 id="Monte-Carlo-Reinforcement-Learning"><a href="#Monte-Carlo-Reinforcement-Learning" class="headerlink" title="Monte-Carlo Reinforcement Learning"></a>Monte-Carlo Reinforcement Learning</h1><h2 id="蒙特卡罗算法"><a href="#蒙特卡罗算法" class="headerlink" title="蒙特卡罗算法"></a>蒙特卡罗算法</h2><p>蒙特卡罗法并不是一种算法的名称，而是对一类随机算法的特性的概括。既然是随机算法，在采样不全时，通常不能保证找到最优解，只能说是尽量找。那么根据怎么做的“尽量”，我们可以把随机算法分成两类：</p><ul><li>蒙特卡洛算法：随机采样的越多，得到的结果<strong>越近似最优解</strong>（概率越大）；</li><li>拉斯维加斯算法：另一类随机算法的思路是采样越多，越<strong>有机会找到最优解</strong>。</li></ul><p>这两个词本身是两座著名赌城，因为赌博中体现了许多随机算法，所以借过来命名。这两类随机算法之间的选择，往往受到问题的局限。如果问题要求在有限采样内，必须给出一个解，但不要求是最优解，那就要用蒙特卡罗算法。反之，如果问题要求必须给出最优解，但对采样没有限制，那就要用拉斯维加斯算法。</p><p>关于蒙特卡罗的例子可以看看这个视频（给了5个案例）：<a href="https://www.youtube.com/watch?v=XRGquU0ZJok">蒙特卡罗 Monte Carlo</a></p><h2 id="蒙特卡罗强化学习"><a href="#蒙特卡罗强化学习" class="headerlink" title="蒙特卡罗强化学习"></a>蒙特卡罗强化学习</h2><p>蒙特卡洛强化学习指：指在不清楚MDP具体细节的情况下，直接基于某个策略从某个状态开始，让个体与环境交互经历完整的状态序列 (episode) ，某状态的价值等于在多个状态序列中以该状态算得到的所有return 的平均。这里所谓<strong>完整的状态序列 (complete episode)**并不要求起始状态一定是某一个特定的状态，但是要求个体最终进入环境认可的某一个终止状态。从这里也能看出MC的局限性在于</strong>要求MDP过程存在终止状态**</p><p><strong>Monte-Carlo Policy Evaluation 的流程</strong></p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course4.1.JPG"></p><p>可以看出，预测问题的求解思路还是很简单的。核心思想就是<strong>用平均收获值代替价值（value = empirical mean return）</strong>，理论上Episode越多，结果越准确。不过有几个点可以优化考虑：</p><ul><li>第一个考虑的点在于：同样一个状态可能在一个完整的状态序列中重复出现，那么该状态的收获该如何计算？</li></ul><p>一种办法是仅把状态序列中第一次出现该状态时的收获值纳入到收获平均值的计算中，这被称为 Fist-Visit Monte-Carlo Policy Evaluation</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course4.2.JPG"></p><p>另一种是针对一个状态序列中每次出现的该状态，都计算对应的收获值并纳入到收获平均值的计算中，这被称为 Every-Visit Monte-Carlo Policy</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course4.3.JPG"></p><p><strong>第二种方法比第一种的计算量要大一些，但是在完整的经历样本序列少的场景下会比第一种方法适用。</strong></p><ul><li>另一个需要考虑的点在于：上面预测问题的求解公式里，我们有一个average的公式，意味着要保存所有该状态的收获值之和最后取平均。这样浪费了太多的存储空间。一个较好的方法是empirical mean的更新可以被写成Incremental Mean的方式，在实际操作时更新平均收获时，不需要存储所有既往收获，而是每得到一次收获，就计算其平均收获。</li></ul><p>通过下面的公式可以更好的理解（相当于在上一次数值的基础上，加上一个带学习率的残差进行更新）：</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course4.4.JPG"></p><p>把这个方法应用于蒙特卡洛策略评估，就得到下面的蒙特卡洛累进更新。在处理非静态问题时，使用这个方法跟踪一个实时更新的平均值是非常有用的，还可以引入参数 $\alpha$ 每得到一轮episode后更新状态价值的速度：</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course4.5.JPG"></p><p>以上就是蒙特卡洛学习方法的主要思想和描述，<em>蒙特卡洛学习方法实际应用并不多</em>。接下来着重介绍实际常用的TD学习方法。</p><h1 id="Temporal-Difference-Learning"><a href="#Temporal-Difference-Learning" class="headerlink" title="Temporal-Difference Learning"></a>Temporal-Difference Learning</h1><h2 id="TD算法流程"><a href="#TD算法流程" class="headerlink" title="TD算法流程"></a>TD算法流程</h2><p>时序差分学习简称TD学习，它的特点如下：和蒙特卡洛学习一样，它也从Episode学习，不需要了解模型本身；但是它可以学习<strong>不完整</strong>的Episode，通过<strong>自举（bootstrapping）</strong>，猜测Episode的结果，同时持续更新这个猜测。</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course4.6.JPG"></p><p>所谓bootstrapping，就是TD算法在估计某一个状态的价值时，用到了以前估计的值，这里很类似Bellman方程的形式。图中TD target包括了模型对价值函数的预测值和环境的实际奖励，对于这个概念的理解可以参考<a href="https://www.bilibili.com/video/BV1BE411W7TA?p=2">这个视频（第二节）</a></p><h2 id="n-step-TD"><a href="#n-step-TD" class="headerlink" title="n-step TD"></a>n-step TD</h2><p>先前所介绍的TD算法实际上都是TD(0)算法，括号内的数字0表示的是在当前状态下往前多看1步，要是往前多看2步更新状态价值会怎样？这就引入了n-step的概念。</p><p>对于n步时序差分来说，和普通的时序差分的区别就在于收获的计算方式的差异。那么既然有这个n步的说法，那么n到底是多少步好呢？如何衡量n的好坏呢？我们将在下一讲讨论。</p><h2 id="MC与TD的对比"><a href="#MC与TD的对比" class="headerlink" title="MC与TD的对比"></a>MC与TD的对比</h2><p><strong>（1）</strong>TD 在知道最终结果之前可以学习，MC必须等到最终结果才能学习；TD 可以在没有终止状态时的持续进行的环境里学习。</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course4.8.JPG"></p><p><strong>（2）</strong> 偏差/方差分析：这也很好理解，MC的方式会经历更为长时间的状态过程，MDP的随机性会对经验平均带来大的方差；而对于TD变换的主要原因在于的即时奖励，方差自然会小但是如果即使奖励不准确会使得对价值函数的估计出现偏差</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course4.9.JPG"></p><p><strong>（3）</strong> 通过比较可以看出，TD算法使用了MDP问题的马尔可夫属性，在Markov 环境下更有效；但是MC算法并不利用马尔可夫属性，通常在非Markov环境下更有效。</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course4.10.JPG"></p><h1 id="三种强化学习算法对比"><a href="#三种强化学习算法对比" class="headerlink" title="三种强化学习算法对比"></a>三种强化学习算法对比</h1><p>Monte-Carlo, Temporal-Difference 和 Dynamic Programming 都是计算状态价值的一种方法，区别在于，前两种是在不知道Model的情况下的常用方法，这其中又以MC方法需要一个完整的Episode来更新状态价值，TD则不需要完整的Episode；DP方法则是基于Model（知道模型的运作方式）的计算状态价值的方法，它通过计算一个状态S所有可能的转移状态S’及其转移概率以及对应的即时奖励来计算这个状态S的价值。</p><p>下面的几张图直观地体现了三种算法运行流程的区别：</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course4.11.JPG"></p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course4.12.JPG"></p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course4.13.JPG"></p><p><strong>关于是否Bootstrapping：</strong>MC 只使用实际收获；DP和TD使用了</p><p><strong>关于是否用样本来计算:</strong> MC和TD都是应用样本来估计实际的价值函数；而DP则是利用模型直接计算得到实际价值函数，没有样本或采样之说。</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course4.14.JPG"></p><p>从<strong>采样深度和广度</strong>两个维度来解释了四种算法的差别，多了一个穷举法。</p><ul><li>当使用单个采样，同时不走完整个Episode就是TD；</li><li>当使用单个采样但走完整个Episode就是MC；</li><li>当考虑全部样本可能性，但对每一个样本并不走完整个Episode时，就是DP；</li><li>当既考虑所有Episode又把Episode从开始到终止遍历完，就变成了穷举法。</li></ul><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course4.15.JPG"></p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Reinforcement Learning</tag>
      
      <tag>AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>David Silver 强化学习教程（3）：动态规划</title>
    <link href="/2020/05/28/David%20Silver%20%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%95%99%E7%A8%8B%EF%BC%883%EF%BC%89%EF%BC%9A%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    <url>/2020/05/28/David%20Silver%20%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%95%99%E7%A8%8B%EF%BC%883%EF%BC%89%EF%BC%9A%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/</url>
    
    <content type="html"><![CDATA[<p>从广义上讲，强化学习是序贯决策问题。在上一节，我们已经将强化学习纳入到马尔科夫决策过程MDP的框架之内，根据是否建立了环境模型（即状态转移概率），可以分为<strong>基于模型的动态规划方法和基于无模型的强化学习方法</strong>。</p><p>DP算法在增强学习领域应用十分有限，因为它们不仅要求理想的环境模型，同时在状态多的情况下导致计算量也非常大，但是在理论方面依然非常重要。 DP算法为本书后面章节的理解提供了必要的基础，强化学习所有的方法都可以看成是为了实现和DP相似的效果，只是弱化已知精确环境模型的假设。</p><h1 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h1><p>动态规划算法是解决复杂问题的一个方法，算法通过把复杂问题分解为子问题，通过求解子问题进而得到整个问题的解。在解决子问题的时候，其结果通常需要存储起来被用来解决后续复杂问题。当问题具有下列特性时，通常可以考虑使用动态规划来求解：</p><ul><li>最优子结构(Optimal substructure)：意味着我们的问题可以拆分成一个个的小问题，通过解决这个小问题，最后，我们能够通过组合小问题的答案，得到大问题的答案</li><li>重叠子问题(Overlapping subproblems)：子问题在复杂问题内重复出现，使得子问题的解可以被存储起来重复利用。</li></ul><p>马尔科夫决定过程（MDP）满足上述的两个属性，可以使用动态规划来求解MDP</p><ul><li>Bellman方程把问题递归为求解子问题，</li><li>价值函数就相当于存储了一些子问题的解，可以复用。</li></ul><p><strong>动态规划求解MDP</strong></p><p>使用动态规划解决MDP问题时，通常假设环境是有限马尔可夫决策过程。也就是说，我们假设环境的状态，动作，和奖励集合有限，且给出了他们的动态特性即转移概率</p><ul><li>动态规划应用于MDP的<strong>规划问题(planning)**而不是学习问题(learning)，我们必须</strong>对环境是完全已知的(Model-Based)**，才能做动态规划</li><li>动态规划对于prediction（评估策略）和control问题（找到最优策略可分为策略迭代和价值迭代）均能求解（定义请看第一章）</li></ul><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course3.1.JPG"></p><h1 id="策略评估求解预测问题"><a href="#策略评估求解预测问题" class="headerlink" title="策略评估求解预测问题"></a>策略评估求解预测问题</h1><p>首先要介绍的是策略评估，<strong>策略评估就是给定任意策略 $\pi$怎么判断该策略到底有多好即计算其状态值函数</strong>。这个评价由基于当前策略的值函数 $v_{\pi}(s)$衡量。下面是整个流程：</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course3.2.JPG"></p><ol><li><p>给定要评估的策略 $\pi$ 和MDP中所有状态的 value function $v_1$，一般是全部置为0。这个初始化不会影响迭代结果，并且它不会影响收敛速率。</p></li><li><p>如果要获得状态 $s$ 的价值函数，需要看在该状态下通过策略 $\pi$ 其状态能转移到了哪些后续状态式 $s^{‘}$ ；而在具体要计算的时候，利用第 $k$ 步迭代得到的这些后续状态 $s^{‘}$ 的价值函数，带入Bellman Expectation Equation，得到新一轮 $k+1$ 步迭代的价值函数</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course3.3.JPG"></p></li><li><p>反复第2步一直到价值函数值恒定不变，这个迭代过程的结果 $v_{\pi}$ 就是对当前策略的评估</p></li></ol><p><strong>示例：Evaluating a Random Policy in the Small Gridworld</strong></p><p>在这节课程中用到的例子是一个最快达到网格中的灰色点，我们从最开始的随机策略开始，对其进行策略评估</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course3.4.JPG"></p><ul><li>状态空间 S：图中灰色方格所示两个位置为终止状态</li><li>行为空间 A：{n, e, s, w} 对于任何非终止状态可以有向北、东、南、西移动四个行为</li><li>转移概率 P：任何试图离开方格世界的动作其位置将不会发生改变，其余条件下将100%地转移到动作指向的状态（即在边界格子时，任何试图冲出边界的行为都会维持在原地，其他情况下移动不会出现打滑走对角线的可能）</li><li>即时奖励 R：任何在非终止状态间的转移得到的即时奖励均为-1，进入终止状态即时奖励为0</li><li>衰减系数 $\gamma$：1</li><li>初始化为随机策略，对于任何非终止状态可以等概率朝4个方向移动，目标是最快达到灰色格子的状态</li></ul><p>迭代过程的详细步骤可以参考知乎叶强大佬的文章： <a href="https://zhuanlan.zhihu.com/p/28084990">迭代法评估4*4方格世界下的随机策略</a></p><center><img src="https://pic3.zhimg.com/v2-0082e5876e2ea59bdcedc7912bb15a3a_b.jpg" style="zoom: 90%;" /></center><p>可以看到，动态规划的策略评估计算过程并不复杂，但是如果我们的问题是一个非常复杂的模型的话，这个计算量还是非常大的。</p><blockquote><p>除了通过迭代进行策略评估外，这个视频还提到了解析解的方法，感兴趣的可以参考<a href="https://www.bilibili.com/video/BV1nV411k7ve?p=3">https://www.bilibili.com/video/BV1nV411k7ve?p=3</a></p></blockquote><h1 id="策略迭代求解控制问题"><a href="#策略迭代求解控制问题" class="headerlink" title="策略迭代求解控制问题"></a>策略迭代求解控制问题</h1><p>现在我们正式介绍最优策略的解法之一，<strong>Policy Iteration策略迭代</strong>，它包括上面介绍的策略评估（policy evaluation）和策略改进（policy improvement）两个步骤。</p><p>现在我们已经通过策略评估确定了一个确定性策略$\pi$的状态价值函数，那么接下来的问题就是：是否可以找到一个更好的策略$\pi^{‘}$。最直接的办法就是对$\pi^{‘}$也进行策略评估得到状态价值函数，但这本身是个很耗时的工作。</p><p>下面要介绍的策略改进定理提供了更加简洁的思路：我们无需对新的策略$\pi^{‘}$直接求价值函数，而是考虑在状态 $s$下强制执行动作 $a=\pi^{‘}(s)$（注意在当前策略$\pi$下并不一定会采取这个动作$a$），然后遵从现有的策略$\pi$并计算出若$q{\pi}(s,\pi^{‘}(s))$的值。若相比于$V_{\pi}(s)$更大，新的策略事实上总体来说也会比较好。</p><p>我们一般采取贪婪策略提升的方法，即新的确定性策略 $\pi^{‘}$是根据当前状态$s$下所有动作中，贪婪地选使得后继状态价值增加最多的行为（即利用评估得到的$V_{\pi}(s)$求出$q{\pi}(s,\pi(s))$并从中选出最大的一项更新策略）</p><p>下面图展示Policy Iteration的过程：</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course3.8.JPG"></p><p>现在我们从理论的角度，来给出Policy Iteration一定会收敛到最优值函数和策略的证明：</p><ul><li>采取贪婪策略提升的方法得到新的策略</li></ul><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course3.9.JPG"></p><ul><li>在新的策略 $\pi^{‘}$ 下，可以得到下述的不等式关系</li></ul><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course3.10.JPG"></p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course3.11.JPG"></p><ul><li>当policy improvement 停止的时候，上述的不等式关系变成全等式。此时也意味着bellman optimal Equation 被满足。找到了最优的策略</li></ul><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course3.12.JPG"></p><p>在small gridworld的例子中结合贪婪策略提升的方法，可以看出策略的不断提升</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course3.5.JPG"></p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course3.6.JPG"></p><p>很多时候，<strong>策略的更新较早就收敛至最优策略，而状态价值的收敛要慢很多</strong>，是否有必要一定要迭代计算直到状态价值得到收敛呢？</p><p>从上面方格的例子中，我们可以看出来$k=3$的时候，策略已经达到最优，虽然此时还没有满足Bellman Optimal Equation的条件，但是最优的policy已经出来了。所以，在这之后我们做的一次次迭代实际上是无用功，Modified Policy Iteration希望解决的就是砍掉这些无用的迭代的过程，我们有以下解决方案：</p><ul><li>引入变量 $\epsilon $ 作为停止条件，在精度允许范围内即可结束</li><li>设定一个固定的策略评估次数$k$，策略评估在$k$次迭代之后就截至。事实上当$k=1$的时候，Policy Iteration算法就变成了接下来介绍的Value Iteration</li></ul><h1 id="价值迭代求解控制问题"><a href="#价值迭代求解控制问题" class="headerlink" title="价值迭代求解控制问题"></a>价值迭代求解控制问题</h1><p>策略迭代存在一个问题，就在于<strong>策略迭代每次迭代都需要进行策略评估，主要时间都花费在策略评估上，而策略评估本身可能需要多次迭代才能收敛</strong>，对一个简单的问题来说，在策略评估上花费的时间不算长；但对复杂的问题来说，这个步骤的时间实在有些长。那么是否可以提前结束策略评估呢？这就引出了下面要介绍的价值迭代。</p><p><strong>最优策略原则</strong></p><p>一个最优的策略，我们可以从两步来思考：</p><ul><li>从状态 $s$ 到下一个状态 $s^{‘}$，采取了最优的动作</li><li>后继状态每一步都按照最优的policy去做，那么我最后的结果就是最优的</li></ul><p>一个策略能够使得状态s获得最优价值，当且仅当：<strong>对于从状态s可以到达的任何状态s’，该策略能够使得状态s’的价值是最优价值：</strong></p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course3.13.JPG"></p><p>我们可以知道我们期望的最终（goal）状态的位置以及反推需要明确的状态间关系，认为它是一个确定性的价值迭代<strong>。</strong>因此，我们可以把问题分解成一些列的子问题，<strong>从最终目标状态开始分析，逐渐往回推，直至推至所有状态。</strong></p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course3.14.JPG"></p><p><strong>价值迭代流程</strong></p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course3.16.JPG"></p><p>有关策略迭代和价值迭代的对比：<a href="https://zhuanlan.zhihu.com/p/26699028">策略迭代和价值迭代</a></p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>我们将这节课学到的一种Prediction方法和两种Control的方法信息总结一下：</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course3.17.JPG"></p><p>上图中时间复杂度的分析，$m$为可选动作，$n$为MDP中的可能状态。</p><p>进一步我们对比下价值迭代和策略迭代，这里借用Stackoverflow的一张图：</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course3.18.JPG"></p><p>DP方法的一个特点是：所有的更新都依赖其后继状态的估计值，这称为<strong>自举（bootstrapping）</strong>。另一个特点就是开篇提到的需要精确知道环境模型。</p><p>对于非常大的问题，DP可能不实用，但与其他解决MDP的方法相比，DP方法实际上非常有效。在接下来的两节笔记中，会介绍<strong>不需要模型也不需要自举的方法——蒙特卡洛法；不需要模型但是需要自举的方法——时间差分法</strong>。</p><h1 id="补充内容：异步动态规划算法"><a href="#补充内容：异步动态规划算法" class="headerlink" title="补充内容：异步动态规划算法"></a>补充内容：异步动态规划算法</h1><p>参考<a href="https://www.cnblogs.com/pinard/p/9463815.html">刘建平的博客</a></p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Reinforcement Learning</tag>
      
      <tag>AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>David Silver 强化学习教程（2）：马尔可夫决策过程</title>
    <link href="/2020/05/15/David%20Silver%20%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%95%99%E7%A8%8B%EF%BC%882%EF%BC%89%EF%BC%9A%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B/"/>
    <url>/2020/05/15/David%20Silver%20%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%95%99%E7%A8%8B%EF%BC%882%EF%BC%89%EF%BC%9A%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="马尔科夫过程"><a href="#马尔科夫过程" class="headerlink" title="马尔科夫过程"></a>马尔科夫过程</h1><p><strong>Markov Property</strong></p><p>是随机过程中的概念，因俄国数学家马尔可夫的研究而得名。它表明在给定现在状态及所有过去状态情况下，只要当前状态可知， 就可以决定未来状态的条件概率分布，所有的历史信息都不再需要（即一个<strong>无记忆</strong>的随机过程）。我们称当前状态具有<strong>马尔科夫性</strong>即具备如下得特性：</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course2.1.PNG"></p><p><strong>Markov Chain</strong></p><p>一个具有有限状态和持续时间，且满足马尔可夫性质的随机过程，称<strong>马尔可夫过程（Markov Process</strong>）或<strong>马尔科夫链（Markov Chain）</strong>。通常是以一个**元组&lt;S,P&gt;**表示，其中S是状态的集合，P是状态转移概率矩阵。</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course2.2.PNG"></p><p><strong>示例——学生马尔科夫链</strong></p><p>David的课程中，将多次用到下面得学生马尔科夫过程作为案例来解释有关概念和计算。</p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course2.3.PNG" style="zoom:80%;" /><p>可以看到从某一状态开始，其后的过程根据状态转移矩阵存在多种可能情况，在强化学习中这样一组状态的转移过程被称为<strong>episode或者trajectory</strong></p><center><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course2.4.JPG" style="zoom:67%;" /></center><p><strong>为什么在强化学习中要引入马尔可夫性</strong></p><p>我们在上篇文章提到了环境的状态转化模型，它可以表示为一个概率模型$P_{ss^{‘}}^{a}$。显然在真实的环境状态转移不仅和前一状态有关，还与上上个以及更早前的状态相关，这一会导致我们的环境转化模型非常复杂难以建模。因此我们需要对强化学习的环境转化模型进行简化，简化的方法就是假设状态转化的马尔科夫性。</p><p>马尔科夫过程（MP）被用于<strong>对完全可观测的环境进行描述</strong>，而几乎所有的强化学习问题都可以被视作为接下来要介绍的马尔可夫决策过程（MDP，即使部分可观测环境问题也可以转化为POMDP），因此理解从马尔可夫性到马尔科夫决策过程是理解强化学习问题的基础。</p><h1 id="马尔科夫奖励过程"><a href="#马尔科夫奖励过程" class="headerlink" title="马尔科夫奖励过程"></a>马尔科夫奖励过程</h1><p>现在我们逐渐加入强化学习中的一些要素来拓展马尔科夫过程，首先在马尔科夫过程的基础上<strong>增加了奖励R和衰减系数γ</strong>，就得到了马尔科夫奖励过程 </p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course2.5.PNG"></p><h2 id="Reward"><a href="#Reward" class="headerlink" title="Reward"></a>Reward</h2><p><strong>奖励函数</strong>：需要注意一下David在这里的表述：在时间点 $t$, agent处于状态 $s$ ，而在 $t+1$ 时刻获得环境反馈的奖励 $R_{t+1}$，因为$s$ 转移过去的下一状态是随机的，因此这里对奖励值取了一次期望得到$R_s$。照此理解起来相当于<strong>离开当前状态 $s$ 获得了奖励</strong>，David指出这是本门课程的习惯表示，如果把奖励改为 <strong>$R{t+1}$</strong> 只要在表述上描述成：$t+1$时刻进入某个状态 $s^{‘}$ 获得的相应奖励即可，本质上意义是相同的。</p><p>下图是例子中各个状态的即时奖励情况</p><center><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course2.6.PNG" style="zoom:80%;" /></center><h2 id="Discount-Factor"><a href="#Discount-Factor" class="headerlink" title="Discount Factor"></a>Discount Factor</h2><p><strong>折扣因子</strong> $\gamma$ 介于 [0, 1]区间，为什么引入衰减系数的原因在于：</p><ul><li>避免在循环或者无限的MDP过程中，产生无穷大或者无穷小的值的值函数，陷入无限循环</li><li>在某些领域如金融学上，立即回报可以赚取比延迟汇报更多的利息，因而更有价值</li><li>远期利益具有一定的不确定性，符合人类和动物更偏爱对立即利益的追求，折扣因子用来模拟这样的认知模式</li></ul><h2 id="Return"><a href="#Return" class="headerlink" title="Return"></a>Return</h2><p>通常译为“<strong>收益</strong>”或”<strong>回报</strong>“，定义为在一个马尔科夫奖励链上从 $t$ 时刻开始，往后所有奖励的有衰减的总和。其中衰减系数体现了对未来的奖励的重视程度。$\gamma$ 接近0，则表明趋向于“近视”性评估；$\gamma$ 接近1则表明偏重考虑远期的利益。</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course2.7.PNG"></p><p>结合上面提到的那张学生马尔可夫链说明Return的计算</p><center><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course2.8.PNG" style="zoom:80%;" /></center><p>从上图也可以理解到，收益是针对一个马尔科夫链中的<strong>某一具体的状态转移过程</strong>来说的。</p><h2 id="State-Value-Function"><a href="#State-Value-Function" class="headerlink" title="State Value Function"></a>State Value Function</h2><p>回报是个随机值，其随机性来源于策略本身和环境。为了评价观测到某一状态的价值，引入<strong>价值函数</strong>的定义：从该状态出发，后续所有可能的状态转移过程的return的期望</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course2.9.PNG"></p><h2 id="Bellman-Equation"><a href="#Bellman-Equation" class="headerlink" title="Bellman Equation"></a>Bellman Equation</h2><p>根据Value Function的定义，可以将其拆分为以下两部分：</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course2.10.PNG"></p><ul><li>第一部分是该状态的即时奖励期望</li><li>另一部分是进入下一可能状态的价值函数值的期望，可以根据状态转移矩阵的概率分布得到</li></ul><p>下图更进一步阐述了贝尔曼方程的递归性质：</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course2.11.PNG"></p><p>以学生马尔可夫过程为例，可以得到如下的推演：</p><center><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course2.12.PNG"  /></center><p>根据系统的n个状态，不难进行扩展得到整个马尔可夫奖励过程Bellman方程的表示：</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course2.13.PNG"></p><p>这本质上是一个线性方程组，可以直接进行矩阵运算得到解析解：</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course2.14.PNG"></p><p>可以看到直接求解的复杂度是$O(n^3)$，适用于小规模的MRP，当状态数目很大时矩阵的求逆会非常困难。大规模MRP的求解通常使用<strong>迭代</strong>算法。常用的方法包括：动态规划Dynamic Programming、蒙特卡洛评估Monte-Carlo evaluation、时序差分学习Temporal-Difference，后文会逐步讲解这些方法。</p><h1 id="马尔科夫决策过程"><a href="#马尔科夫决策过程" class="headerlink" title="马尔科夫决策过程"></a>马尔科夫决策过程</h1><p>在马尔科夫奖励过程基础上增加<strong>动作集合A</strong>，就得到了马尔科夫决定过程，它是这样的一个5元组: </p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course2.15.PNG"></p><p>引入Action之后，最重要的区别在于：原本MRP中全部由概率表示的过程，现在我们有了更多的控制权，这个决策是由agent来决定的；另一个方面，<strong>agent的决策并不能直接决定他下一步进入哪个状态，而是由action和environment共同决定</strong>。</p><p>下图给出学生状态的MDP过程，需要注意<em>图中红色的文字表示的是采取的行为，而不是先前的状态名</em>。对比之前的学生MRP示例可以发现，同一个状态 $s$下采取不同的行为，得到的环境奖励 $R_s^a$ 是不一样的。</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course2.16.PNG"></p><h2 id="Policy"><a href="#Policy" class="headerlink" title="Policy"></a>Policy</h2><p>策略$\pi$是一个概率分布或集合，其元素$\pi(a|s)$代表<strong>在给定状态$s$下采取可能action的可能性</strong>。</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course2.17.PNG"></p><ul><li>一个策略完整定义了个体的行为方式，也就是说定义了个体在各个状态下，所采取的可能行为方式及其概率</li><li>在具有Markov性质的决策中，概率分布只取决于当前的状态，与历史无关</li><li>某一确定的Policy是与时间无关，或者说静态的，只和当前面临状态有关。但是个体可以利用算法更新Policy</li></ul><blockquote><p>注意策略是静态的、关于整体的概念，不随状态改变而改变。变化的是在某一个状态时，依据策略可能产生的具体行为。因为具体的行为是有一定的概率的，策略就是用来描述各个不同状态下执行各个不同行为的概率。</p></blockquote><h2 id="理解MP、MRP、MDP的联系"><a href="#理解MP、MRP、MDP的联系" class="headerlink" title="理解MP、MRP、MDP的联系"></a>理解MP、MRP、MDP的联系</h2><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course2.18.PNG"></p><ul><li>给定一个MDP和策略$\pi$</li><li>MDP中的状态序列可以构成一个马尔可夫过程</li><li>状态和奖励序列组成一个马尔可夫奖励过程</li><li>在这个过程中满足两个方程：<ol><li>在执行某个策略下，状态$s$转移到$s’$发生的概率，等于执行某一个行为的概率与该行为能使状态从$s$转移至$s’$的概率的乘积之和</li><li>同理，当前状态$s$下执行某一指定策略得到的即时奖励，是该策略下所有可能行为得到的奖励与该行为发生的概率的乘积之和</li></ol></li></ul><h2 id="MDP下的两种Value-Function"><a href="#MDP下的两种Value-Function" class="headerlink" title="MDP下的两种Value Function"></a>MDP下的两种Value Function</h2><p>在MDP中, 价值函数可以用来描述针对状态的价值，也可以描述某一状态下执行某一动作的价值。对应<strong>状态价值函数和动作价值价值函数</strong>(严格意义上应该叫状态-动作价值函数的简写)。</p><p>需要注意的是这两种<strong>价值函数的定义都是建立在确定的策略$\pi$上</strong></p><ol><li><p>基于策略$\pi$的状态价值函数 $v_\pi(s)$：表示从状态s开始，遵循策略时所获得的期望收益；反映在执行当前策略$\pi$时，个体处于状态s时的价值大小</p></li><li><p>基于策略$\pi$的动作价值函数 $q_\pi(s,a)$：遵循策略在状态$s$下执行某一具体动作a所获得的期望收益；或者说在遵循策略$\pi$时，衡量对当前状态执行行为a的价值大小。行为价值函数一般都是与某一特定的状态相对应的。</p></li></ol><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course2.19.PNG"></p><blockquote><p>这里需要注意的是关于状态$s$和动作$a$的对应关系，在状态价值函数中后续所有可能产生的$G_t$，受到所采取的策略$\pi$的限制（确定性策略的话期望符号其实可以取消，随机性策略仍然是做了期望加权）；而对于动作价值函数，应该理解为在当前状态$s$下强制执行动作$a$（可能依据当前的策略$\pi$并不会采取该动作，当然后续的状态转移是受到策略影响的）。</p></blockquote><p><strong>MDP两种价值函数的关系</strong></p><p>图中空心较大圆圈表示状态，黑色实心小圆表示的是动作本身。可以看出，在遵循策略$\pi$时，状态s的价值体现为在该状态下，遵循某一策略而采取所有可能行为的价值按行为发生概率的乘积求和</p><center><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course2.21.PNG" style="zoom:88%;" /></center><p>类似的，一个行为价值函数也可以表示成状态价值函数的形式。它表明某一个状态s下采取一个行为a的价值可以分为两部分：其一是离开这个状态的立即奖励，其二是所有进入新的状态的价值与其转移概率乘积的和。</p><center><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course2.22.PNG" style="zoom:93%;" /></center><h2 id="Bellman-Expectation-Equation"><a href="#Bellman-Expectation-Equation" class="headerlink" title="Bellman Expectation Equation"></a>Bellman Expectation Equation</h2><p>把贝尔曼方程与上述两类价值函数之间关系的式子相结合，就能得到MDP下的贝尔曼期望方程（Bellman Expectation Equation）</p><center><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course2.23.PNG" style="zoom:75%;" /></center><center><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course2.24.PNG" style="zoom:80%;" /></center><h2 id="MDP的最优求解"><a href="#MDP的最优求解" class="headerlink" title="MDP的最优求解"></a>MDP的最优求解</h2><p>解决强化学习问题意味着要寻找一个最优的策略让个体在与环境交互过程中获得始终比其它策略都要多的收获，一旦找到这个最优策略我们就解决了这个强化学习问题。</p><p><strong>Optimal Value Function</strong></p><p>首先需要对<strong>最优状态价值函数和最优行为价值函数</strong>给出定义：</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course2.25.PNG"></p><p>可见最优状态价值函数/最优动作价值函数是所有策略下产生的众多状态价值函数中的最大者</p><p><strong>Optimal Policy</strong></p><ul><li>首先需要定义什么是最优策略;</li></ul><p>当对于任何状态$s$，遵循策略$\pi$的价值不小于遵循策略$\pi’$下的价值，则策略$\pi$优于策略$\pi’$：</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course2.26.PNG"></p><p>对于任何MDP，下面几点成立：</p><ol><li>存在一个最优策略，比任何其他策略更好或至少相等</li><li>可能不止一个最优策略，如果有多个最优策略存在，那么对于任意的状态$s$，所有的最优策略有相同的最优价值函数值$v_*(s)$</li><li>与2同理，所有的最优策略具有相同的行为价值函数$q_*(s,a)$</li></ol><ul><li>寻找最优策略</li></ul><p>MDP的最优策略可以根据最优行为价值函数$q_*(s,a)$来确定，我们之前说到Bellman Expectation Equation中的策略都是关于某一状态的动作概率分布，而对于最优策略则是在某一状态下采取能获得最大action-value的动作（即argmax操作，使得原本的随机动作变成确定性动作）</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course2.27.PNG"></p><p><strong>Bellman Optimality Equation</strong></p><p>当取得最优策略时，在上面提到的4个Bellman Expectation Equation需要进行改动，得到下面Bellman Optimality Equation（把里面的求状态期望改成取argmax的操作）</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course2.28.PNG"></p><p>虽然MDP可以直接用方程组来直接求解简单的问题，但是更复杂的问题却没有办法求解，因此我们还需要寻找其他有效的求解强化学习的方法。下一篇讨论用动态规划的方法来求解强化学习的问题。</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Reinforcement Learning</tag>
      
      <tag>AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>David Silver 强化学习教程（1）：强化学习简介</title>
    <link href="/2020/05/07/David%20Silver%20%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%95%99%E7%A8%8B%EF%BC%881%EF%BC%89%EF%BC%9A%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/"/>
    <url>/2020/05/07/David%20Silver%20%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%95%99%E7%A8%8B%EF%BC%881%EF%BC%89%EF%BC%9A%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="写在最前面"><a href="#写在最前面" class="headerlink" title="写在最前面"></a>写在最前面</h1><p>人工智能领域无疑是近些年各个行业争相追捧的热点，我一个原本搞通信的现在也在逐渐学习AI的知识，毕竟现在通信的理论基础已经发展遇到瓶颈了，除非再出现一个祖师爷香农级别的人物引领一波理论革命。上一阶段的人工智能热潮，按我个人理解是建立在大数据基础上的，通过机器从带有标签的大量数据中提取特征，学习模式从而完成预测和分类任务。最常见应用就包括计算机视觉、自然语言处理，这两个领域机器已经能做到达到甚至超越人类的性能，而无论公司和从业者都多到离谱，无疑已是一片红海。</p><p>另一派人工智能的技术则以强化学习为代表（当然这里头也涉及到多种技术的融合）。监督式的学习毕竟以人类标记作为准测，机器的性能天花板不可能超过人类。而强化学习才是真正能赋予了机器认知和意识的技术，实现真正意义上的“强人工智能”。以谷歌DeepMind团队开发的AlphaGo系统在2016年和2017年先后击败世界围棋高手李世石和柯洁为标志事件，强化学习算法引起了各个领域的广泛关注，并且取得了不少的研究成果。</p><p>对于各行业从业者，学会强化学习的知识并且用于自己的研究领域无疑是一个迫切的需求。而早在2015年作为领导AlphaGo项目的David Silver就在 UCL 开设了课程并把视频发布到了YouTube上，较为系统地介绍了强化学习的各种思想、实现算法。本系列文章是对于David 所授课程的学习笔记，力求尽量还原教学内容并穿插自己的理解。b站有配上中文字幕<a href="https://www.bilibili.com/video/BV1kb411i7KG?from=search&seid=4606460319322526728">教学视频</a></p><p>本笔记的撰写参考了以下的文章：</p><ul><li><a href="https://zhuanlan.zhihu.com/reinforce">David Silver 强化学习公开课中文讲解及实践</a></li><li><a href="https://zhuanlan.zhihu.com/p/50478310">David Silver 增强学习——笔记合集</a></li><li><a href="https://www.cnblogs.com/pinard/p/9385570.html">强化学习知识整理</a></li></ul><p>关于参考书籍，David在本课程建议的参考书籍主要有两本：</p><ul><li><a href="https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf">《An Introduction to Reinforcement Learning》</a>, （被誉为强化学习教父的Richard S. Sutton编写的经典书籍，也是David Silver的老师，这门课程基本按照这本书的逻辑来），这本书有人翻译成了中文：<a href="https://rl.qiwihui.com/zh_CN/latest/index.html">https://rl.qiwihui.com/zh_CN/latest/index.html</a></li><li><a href="https://sites.ualberta.ca/~szepesva/papers/RLAlgsInMDPs.pdf">《Algorithms for Reinforcement Learning》</a>，（全书 200+页，较为精简，重视数学逻辑和严格推导，适合喜欢啃公式的同学）</li></ul><h1 id="强化学习简介"><a href="#强化学习简介" class="headerlink" title="强化学习简介"></a>强化学习简介</h1><p><strong>强化学习框架</strong></p><p>下图简单阐述了强化学习的基本框架：智能体（Agent，即图中的大脑）需要通过和环境交互学习解决某项任务。首先智能体通过对环境的观察（observation）并依据观察结果采取一个动作（action），动作会对环境产生影响从而使环境发生改变，同时环境也会对行为进行反馈，这个反馈通常可以被抽象为一个数值，称为即时奖励（reward）。</p><p>智能体不断重复以上过程与环境交互吧并记录下交互的历史数据，预设定的学习算法会使用收集到数据改善自身的动作策略。在经过若干次学习后，智能体能最终能很好的适应环境并学得完成相应任务的最优策略（optimal policy）。</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course1.1.JPG"></p><p><strong>强化学习与其他机器学习的联系</strong></p><p>如果你对常见的机器学习方法（machine learning）有所涉猎，根据上面对强化学习的描述，可以看出相比于其他的机器学习算法，强化学习具备以下的特点：</p><ul><li>不存在监督者，而是通过和环境交互来获得奖励</li><li>反馈可能存在延迟，当前步骤采取动作带来的效果并不会立即见效（所以一般在实际操作中会设定一个强化学习过程的持续时间）</li><li>数据非独立同分布的：我们得到的决策过程，我们获取的每一次数据都不是独立同分布(i.i.d)的，他是一个有先后顺序的数据序列</li><li>动作对之后的结果能够产生影响：在决策过程中存在先后顺序，当前动作的不同导致下一次得到完全不同的数据</li></ul><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course1.2.PNG"></p><p>下面这张图进一步说明了强化学习和其他机器学习方法之间的关系：</p><center><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course1.15.PNG" style="zoom:67%;" /></center><h1 id="强化学习中的基本概念"><a href="#强化学习中的基本概念" class="headerlink" title="强化学习中的基本概念"></a>强化学习中的基本概念</h1><p>强化学习入门困难的一点在于其术语非常多且容易混淆，有必要对这些基本概念做详细解释</p><h2 id="Reward"><a href="#Reward" class="headerlink" title="Reward"></a>Reward</h2><p>奖励是环境对智能体采取动作做出的反馈，是一个<strong>标量</strong>；它反映了每一步决策的好坏情况；智能体的目标就是最大化累积奖励。</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course1.3.JPG"></p><p>强化学习本质上是一个<strong>序贯决策过程</strong>，对于任何一个强化学习任务，需要进行以下的考量</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course1.4.PNG"></p><h2 id="Agent-and-Environment"><a href="#Agent-and-Environment" class="headerlink" title="Agent and Environment"></a>Agent and Environment</h2><p>智能体和环境的交互过程如下：</p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course1.5.PNG" style="zoom:80%;" /><ul><li>agent观测环境（observation）并获得环境对其以往动作的反馈（reward），以此为输入，根据内置的算法进而采取对应的行动（action）</li><li>observation是外部环境产生的，可被agent观察到的情况，<strong>不一定等同于environment的内部运行机制</strong>，实际上很多情况下我们也不需要详细知道环境是怎么运作的</li><li>每一个action产生之后会对environment产生作用，影响到下一步骤观测的observation，并且反馈agent相应的reward</li></ul><h2 id="History-and-State"><a href="#History-and-State" class="headerlink" title="History and State"></a>History and State</h2><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course1.6.PNG"></p><ul><li>历史是截至时间t为止所能观察到的变量信息，是一个包含过去观测、动作、奖励的序列</li><li>状态是用来规划将来的已有信息，可以看作<strong>是对历史的总结，因此可以被视作关于history的函数</strong>。State相对于history而言最大的好处在于他的信息量很少，实际上，我们也不需要根据所有的历史信息来决策下一步该采取怎样的action（在之后的马尔科夫状态中会提到历史信息的无记忆性）</li></ul><p><strong>3种不同的State</strong></p><ol><li><p><strong>Environment State</strong> $S_t^e$：是真正的环境所包含的信息，一般对agent并不完全可见。实际上，个体有时候也不需要知道环境状态的全部细节，一是因为agent是根据环境反馈的观测/奖励来修改自己的策略；二是即使环境状态对个体完全可见的，这些信息中也可能包含着一些无关成分；</p></li><li><p><strong>Agent State</strong> $S_t^a$：包括个体可以使用的，用来决定未来动作的所有信息。我个人理解是Agent自己对Environment State的解读与翻译，它可能不完整，但我们的确是指望着这些信息来运行强化学习算法的决策</p></li><li><p><strong>Information State</strong>：又称Markov状态，这个概念更多是强调状态的某种性质，与前面的两种State并不形成并列关系。如果现在的状态已经包含了预测未来所有的有用的信息，换句话讲可以丢弃掉历史信息中跟决策影响无关的成分。则它具有马尔科夫性，满足如下定义：</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course1.7.PNG"></p></li></ol><h2 id="Observation-and-Environment"><a href="#Observation-and-Environment" class="headerlink" title="Observation and Environment"></a>Observation and Environment</h2><p>环境可以分为两种：</p><p><strong>1. Fully Observable Environments</strong></p><p>完全可观察环境下，agent能够直接观察到environment state，即满足图中的等式关系。这是一个很理想化的情况，现实中很多复杂问题是不具备这个条件的。同时根据定义，此时的环境是一个<strong>MDP问题：Markov decision process</strong>。也是强化学习最核心的问题。</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course1.8.PNG"></p><p><strong>2. Partially Observable Environments</strong></p><p>部分可观察环境中，Observation state 不等于 environment state，我们只能看到部分信息，或者只能看到一些现象，这也是大多数强化学习问题的场景。这类问题被称为<strong>POMDP问题：partially observable Markov decision process</strong>。所以此时想要解决问题的话Agent必须自己对环境进行解读，自己去探索。对于这类问题David指出一般有以下的解决办法：</p><ul><li>记住所有的历史状态</li><li>使用贝叶斯概率，推导出产生当前环境状态的概率，为此我们需要记录所有环境状态的概率值</li><li>使用递归神经网络，将最近的状态和观测进行组合来推演</li></ul><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course1.9.PNG"></p><h2 id="Agent的组成要素"><a href="#Agent的组成要素" class="headerlink" title="Agent的组成要素"></a>Agent的组成要素</h2><p>Agent涉及到三个组成要素：策略（Policy），价值函数（Value Function）和模型（Model），但要注意这三要素不一定要同时具备。</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course1.10.PNG"></p><p><strong>1. 策略 Policy</strong></p><p>策略是决定个体行为的机制。是<strong>从状态到动作的一个映射</strong>。有具体两种表现形式：</p><ul><li><p>确定性的（Deterministic）：在某一特定状态确定对应着某一个行为</p></li><li><p>随机的（Stochastic）：在某一状态下，对应不同行动有不同的概率。随机性的行为更具鲁棒性，因为在一些对抗类的场景下（下围棋），如果agent采取确定性的策略，很容易被对手猜到并作出对付方案</p></li></ul><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course1.11.PNG"></p><p><strong>2. 价值函数 Value Function</strong></p><ul><li>agent在学习过程中需要对面临许多不同的状态，因此要预测某个状态下（或在该状态下状态采取某一动作）可能获得未来的reward的期望值。这个期望值是一个关于状态的函数State-Value function（或关于状态和动作的函数：Action-Value function，在之后笔记的第二章会更详细解释）</li><li>价值函数<strong>是建立在采取某一个策略基础上的</strong>，在不同的策略下即便处于同一状态的，所获得价值并不相同</li></ul><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course1.12.PNG"></p><p><strong>模型 Model</strong></p><p>个体对环境的一个建模，相当于agent“脑补”的一个环境。它体现了<strong>个体是如何思考环境运行机制</strong>的（how the agent think what the environment was.），个体希望模型能模拟环境与个体的交互机制。</p><p>模型至少要解决两个问题：一是<strong>预测状态转移概率</strong>：另一项工作是<strong>预测环境的反馈（即时奖励）</strong>：</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course1.13.PNG"></p><p>*<em>[注]**：</em>模型并不是构建agent所必需的，很多强化学习算法并不试图（依赖）构建一个模型。模型仅针对agent的组成而言，环境实际运行机制称为*<em>环境动力学(dynamics of environment)**，它唯一明确agent下一个状态和所得的即时奖励。</em></p><p><strong>Agent的分类</strong></p><ol><li>仅基于价值函数的 <strong>Value Based</strong>：在这样的个体中，有对状态的价值估计函数，但是没有直接的策略函数，策略函数由价值函数间接得到。</li><li>仅直接基于策略的 <strong>Policy Based</strong>：这样的个体中行为直接由策略函数产生，个体并不维护一个对各状态价值的估计函数。</li><li>演员-评判家形式 <strong>Actor-Critic</strong>：个体既有价值函数、也有策略函数。两者相互结合解决问题。</li></ol><p>此外，根据个体在解决强化学习问题时是否建立一个对环境动力学的模型，将其分为两大类：</p><ol><li><strong>Model free</strong>: 这类个体并不视图了解环境如何工作，而仅聚焦于价值和/或策略函数。</li><li><strong>Model based</strong>：个体尝试建立一个描述环境运作过程的模型，以此来指导价值或策略函数的更新。</li></ol><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course1.14.PNG"></p><h1 id="强化学习算法中的几对概念"><a href="#强化学习算法中的几对概念" class="headerlink" title="强化学习算法中的几对概念"></a>强化学习算法中的几对概念</h1><h2 id="Learning-amp-Planning"><a href="#Learning-amp-Planning" class="headerlink" title="Learning &amp; Planning"></a>Learning &amp; Planning</h2><ul><li>学习：<strong>环境初始时是未知的</strong>，个体不知道环境的信息，只能通过和环境来互动得知我们的action会造成什么样的改变，逐渐改善其行为策略。</li><li>规划: <strong>环境如何工作对于个体是已知或近似已知的</strong>，个体并不与环境发生实际的交互，而是利用其构建的模型进行计算，在此基础上改善其行为策略。Planning 问题可以使用动态规划来解决，在本系列的第三部分我们会具体谈到这个方法。</li></ul><p>一个常用的强化学习问题解决思路是，先学习环境如何工作，也就是了解环境工作的方式，即学习得到一个模型，然后利用这个模型进行规划。</p><h2 id="Exploration-amp-Exploitation"><a href="#Exploration-amp-Exploitation" class="headerlink" title="Exploration &amp; Exploitation"></a>Exploration &amp; Exploitation</h2><p>强化学习是一个不断试错，然后减少错误率的过程。所以这里存在一个矛盾，当我们存在一个相对比较好的解决方案时，我们应该选择沿用我们的解决方案，还是选择尝试新的未知的路径，这个路径可能有很高的错误率，也可能有更好的解决方案。如何进行两者的平衡，就是Exploration和Exploitation的问题</p><ul><li>Exploration(探索)：倾向于探索环境中新的信息</li><li>Exploitation(利用)：倾向于利用已知的信息来获取最大reward</li></ul><h2 id="Prediction-amp-Control"><a href="#Prediction-amp-Control" class="headerlink" title="Prediction &amp; Control"></a>Prediction &amp; Control</h2><p>在强化学习里，我们经常需要先解决关于预测（prediction）的问题，而后在此基础上解决关于控制（control）的问题。实际上，这两者是递进的关系。</p><ul><li><p>prediction：<strong>给定一个policy</strong>，评价遵循该策略下agent能获得多大的奖励，可以看成是求解在给定策略下的价值函数（value function）的过程。</p></li><li><p>control：<strong>在没有policy的前提下</strong>，直接找出一个好的策略来最大化未来的奖励。</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Reinforcement Learning</tag>
      
      <tag>AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>理解信道衰落、相干带宽、相干时间</title>
    <link href="/2020/02/24/%E6%97%A0%E7%BA%BF%E4%BF%A1%E9%81%93%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/"/>
    <url>/2020/02/24/%E6%97%A0%E7%BA%BF%E4%BF%A1%E9%81%93%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/</url>
    
    <content type="html"><![CDATA[<h1 id="无线信道衰落的分类"><a href="#无线信道衰落的分类" class="headerlink" title="无线信道衰落的分类"></a>无线信道衰落的分类</h1><p>无线通信相比有线通信，存在着两个显著的特点使得其问题更为复杂。</p><ol><li>无线信道的状态是随时间不断变化的</li><li>无线通信的环境是开放的，所有用户传输的信号都处在同一个环境下，会造成对别的用户的干扰</li></ol><p>电磁波作为传输载体，存在着多种的传播方式：直射、散射、反射、绕射等，这些都会对信号的强度造成影响。无线信号的衰减方式主要可分为：</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/wireless%20fading.png"></p><ul><li>大尺度衰落：<ul><li>自然衰减（路径损耗）：一般可认为信号功率与传输距离呈现$1/r^2$关系衰减（自由空间或者近距离），或者与距离呈指数递减关系：$r^{\alpha}$（实际的传输环境）</li><li>阴影衰落：信号传输中遇到起伏的地形，建筑物等，因为阻塞而造成的衰减</li></ul></li><li>小尺度衰落：<ul><li>多径效应：传输环境中存在多条通信路径，各条发射波到达接收机的时间，或者说相位各不相同，在接收点叠加造成剧烈的变化</li><li>多普勒效应：由于移动导致接受信号频率的偏移，向发射端移动时频率会增加，而远离时会减小，且移动速度越高，所产生的效应越大</li></ul></li></ul><p>大尺度、小尺度是针对移动程度来说的。一般来讲，小尺度在很短的移动距离内（可认为与信号的波长相当），而大尺度衰落随移动变化较为缓慢，一般通过中继放大器、直放站、室内分布系统等来补偿衰落。</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/various%20fading.JPG"></p><h1 id="时延扩展与相干带宽"><a href="#时延扩展与相干带宽" class="headerlink" title="时延扩展与相干带宽"></a>时延扩展与相干带宽</h1><p>由于多径传输的原因，假如在发送端发送一个窄的脉冲信号，在接收端会接收多个脉冲，本来最短时延是沿最短路径传输所消耗的时间，现在因为多条路径长短不一，所以时延被扩展了，这也称为信道的**时间弥散性（time dispersion)**。通常将最后一个到达的脉冲，和最先到达的脉冲的时延差，称为最大时延扩展，用$\tau_{max}$来表示。</p><center><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/time%20spread.png" style="zoom: 67%;" /></center><ul><li><p>从时域上看，如果这个时延扩展大于两个发送脉冲之间的时间间隔，则会对下一个脉冲的接收产生干扰。，造成符号间干扰即码间串扰 **Inter Symbol Interference，ISI)**，</p><p>要避免这种干扰，就要将发送符号之间的周期$T$扩大。扩大多少呢？至少是大于最大时延扩展: $T_{min}&gt;\tau_{max}$，这样多径时延的影响就很小，没有符号间干扰。根据周期信号的时域频域关系，应该存在一个最大的频带宽度$f_{c}=1/T_{min}$，称为为<strong>相干带宽</strong>，它约等于多径时延的倒数。</p></li><li><p>从频域上看，即<strong>信号带宽或者信号发送速率远大于信道的相干带宽时，</strong>信号通过无线信道后某些频率成分信号的幅值可以增强（相位相同，幅值叠加），而另外一些频率成分信号的幅值会被削弱（相位相反，幅值相消），引起信号波形的失真，此时就认为发生了<strong>频率选择性衰落。</strong> 当信号满足小于相干带宽的要求，则认为接收端的信号通过无线信道后，各频率成分幅度很接近（称为“相干”），即经历了<strong>平坦衰落</strong></p><p>频率选择性衰落，实质是一样的，在时域中是符号间干扰，表现形式是信号波形会发生畸变，换算到频域中来看，就是有些频率分量的强度会加强，有些会减弱。<strong>相干带宽是无线信道的一个特性</strong>， 至于信号通过无线信道时， 是出现频率选择性衰落还是平坦衰落， 这要取决于信号本身的带宽与相干带宽的大小关系。</p></li><li><p>应用：对于高速通信（很高的信号带宽），为了对抗频率选择性衰落，人们采用了正交频分复用（OFDM）技术，将宽带信号分成很多子带，频域上分成很多子载波发送出去，每个子带的信号带宽由于小于相干带宽，从而减少甚至避免了频率选择性衰落。</p></li></ul><h1 id="多普勒扩展与相干时间"><a href="#多普勒扩展与相干时间" class="headerlink" title="多普勒扩展与相干时间"></a>多普勒扩展与相干时间</h1><p>多普勒频移的计算公式如下，其 中$f_c$表示载波频率， $c$表示光速，$f_m$ 表示最大多普勒频移， $v$表示移动台的运动速度，$\theta$表示信号到达角（物体前进方向与信号到达方向的夹角）。</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/doppler%20shift.png"></p><p>由于多普勒频移，导致了一频率信号经过时变衰落信道之后会呈现为具有一定带宽和频率包络的信号，见下图。这又可以称为信道的<strong>频率弥散性(frequency dispersion)</strong></p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/frequence%20dispersion.png"></p><p><strong>相干时间</strong>被定义为：$T_c \approx1/f_d$，等于多普勒频移的倒数。它是指<strong>信道状态维持不变的时间</strong>，或者说信道的冲激响应维持不变的时间间隔。</p><ul><li>从时域上看，若<strong>符号的持续时长</strong>远大于信道的相干时间，多普勒扩展带宽内所对应信号的相位将发生很大的变化，导致在一个符号时间内接收端到达的同一信号的波形产生很大的变化，产生<strong>时间选择性衰落，也称为快衰落</strong>；否则，在此时间内接收信号的包络的相位变化将很小，信号的幅度变化也就很小，产生<strong>非时间选择性衰落，也称为慢衰落。</strong></li><li>从频域上看，若信号带宽远小于多普勒扩展带宽，那由于频移使得相邻的频率分量之间相互干扰，造成<strong>载波间干扰（ICI）。</strong></li></ul><p>参考David Tse的《无线通信基础》：多普勒扩展对应的频率就是信号变化的包络，这个包络的周期即相干时间正比于就是多普勒扩展带宽的倒数。</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david%20tse.png"></p><ul><li>应用：从发射分集的角度来理解：时间分集要求两次发射的时间要大于信道的相干时间，即如果发射时间小于信道的相干时间，则两次发射的信号衰落特性完全相似，会被接收端认为是同一个信号。分集抗衰落的作用就不存在了。</li></ul>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>无线通信</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>[论文阅读01] Neurosurgeon：Collaborative Intelligence Between the Cloud and Mobile Edge</title>
    <link href="/2019/12/16/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%8ANeurosurgeon%EF%BC%9ACollaborative%20Intelligence%20Between%20the%20Cloud%20and%20Mobile%20Edge%E3%80%8B/"/>
    <url>/2019/12/16/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%8ANeurosurgeon%EF%BC%9ACollaborative%20Intelligence%20Between%20the%20Cloud%20and%20Mobile%20Edge%E3%80%8B/</url>
    
    <content type="html"><![CDATA[<blockquote><p>论文出处：2017 <strong>ASPLO</strong> (Architectural Support for Programming Languages and Operating Systems)会议，是计算机体系结构方向的顶级学术会议，<a href="https://web.eecs.umich.edu/~jahausw/publications/kang2017neurosurgeon.pdf">《Neurosurgeon: Collaborative Intelligence Between the Cloud and Mobile Edge》</a></p></blockquote><h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h1><p>目前越来越多的智能应用程序，使用语音和图像类型的数据作为输入。比如智能个人助理（Apple Siri、Microsoft Cortana），智能家居和可穿戴设备、导航应用等，人们与移动设备交互模式正在发生迅速改变，预计将取代传统的基于文本的输入形式。</p><p>这些应用的实现依赖准确且高度复杂的机器学习技术，其中最常见的是深度神经网络（DNN）。早期的工作认为：传统的移动设备不能支持这种大量的计算，以满足合理的延迟和能量消耗。Web服务提供商用于智能应用程序的现行方法，是把用户的移动设备生成的查询发送到云进行处理，在远端的高性能云服务器上托管所有计算。然而利用这种方法，大量数据（例如，图像，视频和音频）经由无线网络和回程链路上载到服务器，导致高等待时间和能量成本。</p><p>庆幸的是，现代移动硬件的性能和能效通过强大的移动SoC集成继续得到改善。受此启发，本文的作者重新审视了移动和云之间智能应用程序的计算细分。即在运行以神经网络为支撑的应用程序任务时，将计算任务拆解为server-side和edge-side两部分，其中server-side在数据中心的服务器里执行，edge-side则在终端设备上执行。</p><p><img src="https://cdn.jsdelivr.net/gh/xiangli-bjtu/Image-hosting-site/img/1.PNG"></p><p>这项工作要处理的主要问题包括：</p><ol><li>在当今的移动平台上执行大规模智能工作负载的可行性如何？</li><li>在何种情况下，通过无线网络传输语音和图像数据的成本过高，而无法发挥云处理的合理性？</li><li>在为需要大量计算的智能应用程序提供处理支持方面，移动边缘应当扮演什么角色？</li></ol><p>作者使用8个基于DNN的智能应用程序进行试验，这些应用程序涵盖了视觉，语音和自然语言领域。作者发现：终端设备与数据中心的网络连接带宽，设备的计算能力，DNN模型的结构都会影响到计算任务的拆解方式。拆解的粒度是神经网络的layer。这种任务划分策略的考虑，可以影响端到端延迟和移动能源效率。这也可以被认为是一个带约束的优化问题，优化目标是对计算任务在两个计算结点（终端和服务器端）之间进行拆分，约束则包括网络结构、网络带宽以及设备的计算能力。同时，将计算推到云之外的移动设备上，也提高了数据中心的吞吐量，允许给定的数据中心支持更多的用户查询，为移动设备和云系统创造了双赢的局面。</p><p>作者为此设计了一个轻量级动态调度系统：Neurosurgeon。它是一个跨越云和移动平台的系统，可自动识别DNN中的理想分区点，并协调移动设备和数据中心之间的计算分配。针对8个DNN应用程序的评估表明，使用Neurosurgeon，平均可将端到端延迟提高3.1倍，将移动能耗降低59.5％，并将数据中心吞吐量提高1.5倍。</p><h1 id="2-Background"><a href="#2-Background" class="headerlink" title="2. Background"></a>2. Background</h1><p>本部分，主要是对深度神经网络（DNN）的概述，作者描述计算机视觉，语音和自然语言处理等应用程序，如何利用DNN作为其核心机器学习算法。</p><p><img src="https://cdn.jsdelivr.net/gh/xiangli-bjtu/Image-hosting-site/img/2.PNG"></p><h1 id="3-Cloud-only-Processing"><a href="#3-Cloud-only-Processing" class="headerlink" title="3. Cloud-only Processing"></a>3. Cloud-only Processing</h1><h2 id="Experimental-setup"><a href="#Experimental-setup" class="headerlink" title="Experimental setup"></a>Experimental setup</h2><p>介绍了本文实验中，移动端和服务器端采用的硬件平台：</p><p><img src="https://cdn.jsdelivr.net/gh/xiangli-bjtu/Image-hosting-site/img/3.PNG"></p><p><img src="https://cdn.jsdelivr.net/gh/xiangli-bjtu/Image-hosting-site/img/4.PNG"></p><p>以及采用的DNN网络的搭建框架：</p><p><img src="https://cdn.jsdelivr.net/gh/xiangli-bjtu/Image-hosting-site/img/5.PNG" alt="5"></p><h2 id="Examining-the-Mobile-Edge"><a href="#Examining-the-Mobile-Edge" class="headerlink" title="Examining the Mobile Edge"></a>Examining the Mobile Edge</h2><p>本文作者以经典的AlexNet网络（一个典型的用于图像分类的卷积神经网络）作为示例，网络以152KB图像作为输入。在通信延迟、计算延迟、端到端延迟和能耗方面进行对比。对于无线通信，使用TestMyNet软件在多个移动设备上测量3G，LTE和Wi-Fi的带宽。</p><p><img src="https://cdn.jsdelivr.net/gh/xiangli-bjtu/Image-hosting-site/img/6.PNG"></p><p>先看时延这一指标：</p><ul><li><strong>通信延迟</strong> ：图3a显示了通过3G，LTE和Wi-Fi上传输入图像的延迟。表明网络类型对于实现将数据传送至云端的低延迟至关重要。</li><li><strong>计算延迟</strong>：图3b显示了在移动CPU，GPU和云GPU上运行AlexNet网络的计算延迟。可以看出在移动设备上运行神经网络的性能还是和云端服务器存在差距；移动设备上GPU处理要强过CPU处理；注意到，即便移动CPUs上运行AlexNet处理图像的时间，仍然比通过3G上传输数据输入快2.3倍。</li><li><strong>端到端延迟</strong> ：图3c显示了仅在云端处理和仅在移动设备上处理，两种方式所需的总延迟，每个条形顶部的注释是用于计算所花费的端到端延迟的占比。<ul><li>使用云服务器进行全部的计算时，结果表明计算所消耗的时间仅占全部时间的6%，而剩余的94%都消耗在数据传输上。</li><li>只要移动设备拥有可用的GPU，在本地GPU上实施所有的计算操作能够带来最佳的体验（总延迟时间最短）；同时，在LTE和Wi-Fi网络条件下，传输至云端处理要比仅用移动设备CPU进行全部的计算操作要更好（系统延迟时间更少）。</li></ul></li><li><strong>能耗</strong>：如果移动设备连接的是Wi-Fi网络，最低的电量损耗方案是发送相应的数据到云服务器并让其进行全部的计算操作。但如果连接的是3G或LTE网络，并且该移动设备有可用的GPU，那么在本地GPU上实施全部的计算操作这一方案所导致的电量消耗，会比数据传输且在云服务器上实施全部的计算操作这一方案更低。</li></ul><h1 id="4-Fine-grained-Computation-Partitioning-细粒度计算分区"><a href="#4-Fine-grained-Computation-Partitioning-细粒度计算分区" class="headerlink" title="4. Fine-grained Computation Partitioning 细粒度计算分区"></a>4. Fine-grained Computation Partitioning 细粒度计算分区</h1><p>上一章所有计算都实施在云服务器或移动设备上，这两种“相对极端”的方法之间，或者说在数据传输和实施计算两者之间是否存在一种折中。显然，DNN分层级的网络结构，提供适合于分区计算的抽象概念。</p><h2 id="Layer-Taxonomy"><a href="#Layer-Taxonomy" class="headerlink" title="Layer Taxonomy"></a>Layer Taxonomy</h2><p>这一小节主要是对目前DNN中存在的各种类型的层和其功能的简要介绍，涉及深度学习有关的知识。包括：Fully-connected Layer、Convolution &amp; Local Layer、Pooling Layer、Activation Layer、normalization layer、softmax layer、argmax layer、dropout layer等。</p><h2 id="Characterizing-Layers-in-AlexNet"><a href="#Characterizing-Layers-in-AlexNet" class="headerlink" title="Characterizing Layers in AlexNet"></a>Characterizing Layers in AlexNet</h2><p>首先研究AlexNet中每个层的数据和计算特征（在本节及后续部分中，在移动和服务器平台中均使用GPU），将得到如下的统计图。（浅色柱）显示了移动GPU上按顺序执行AlexNet每个层的延迟，（深色柱）显示了每层输出数据的大小，这也是下一层的输入。</p><p><img src="https://cdn.jsdelivr.net/gh/xiangli-bjtu/Image-hosting-site/img/7.PNG"></p><ul><li><p>每一层都有不同的计算时间和数据产生开销。</p></li><li><p>卷积（conv）和全连接层（fc）是最耗时的层，占总执行时间的90％以上。</p></li><li><p>中间的卷积层（conv3和conv4）比早期的卷积层（conv1和conv2）花费更长的时间。这是因为后面的卷积层会使用更多数量的滤波器以提取更强的特征，从而增加计算量。</p></li><li><p>AlexNet的前几层会生成大量输出数据，而池化层（pool）会将数据数量锐减，数据数量通过激活层保持不变（relu1-relu5），最后的几层（位于深层的全连接层，softmax，argmax）会逐渐减小数据大小直到最后将数据减少为一个分类标签。</p></li></ul><p>对于AlexNet这种结构的DNN来说，位于网络前端的层产生较大的数据量，而后端的层则带来了较大的计算开销。</p><h2 id="Layer-granularity-Computation-Partitioning-层粒度计算分区"><a href="#Layer-granularity-Computation-Partitioning-层粒度计算分区" class="headerlink" title="Layer-granularity Computation Partitioning 层粒度计算分区"></a>Layer-granularity Computation Partitioning 层粒度计算分区</h2><p>下面研究如果各个网络层分割开会发生什么呢？（即在移动设备上处理模型的前n层，再把得到的第n层的输出结果传输至云服务器上进行之后的计算，最后再将输出结果传输至移动设备上）在本节中，使用Wi-Fi作为无线网络配置。</p><p>在下图中的每个条形，意味着在这一层之后进行分区的端到端延迟和移动能量消耗。那么，最左边的条表示发送原始输入进行云端处理；最右边的条是在移动设备上本地执行整个DNN。</p><p><img src="https://cdn.jsdelivr.net/gh/xiangli-bjtu/Image-hosting-site/img/8.PNG" alt="8"></p><ul><li><strong>延迟分区</strong> ： 如果在前端进行分区，则数据传输主导端到端延迟，这与之前观察到的数据大小在DNN早期阶段的变化趋势是一致的。在后端进行分区可以提供更好的性能，这样可以最大限度地减少数据传输开销，同时后端网络层需要大量的计算，可以利用功能强大的云端服务器执行。在AlexNet使用移动GPU和Wi-Fi的情况下，在pool5和fc6层之间的分区实现了最低延迟，比全部传送到云处理上提高了2.0倍 。</li><li><strong>能量分区</strong> –：与延迟类似，由于无线数据传输的高能源成本，转移仅用于云的处理的输入并不是最节能的方法。 如图6b所示，DNN中间的分区实现了最佳的移动能耗，比纯云方法节能18％。</li></ul><h2 id="Generalizing-to-More-DNNs"><a href="#Generalizing-to-More-DNNs" class="headerlink" title="Generalizing to More DNNs"></a>Generalizing to More DNNs</h2><p>作者进一步将实验扩展到7个更智能的应用程序（7个不同结构的DNN），以研究它们的数据和计算特性及其对计算分区的影响。</p><p><img src="https://cdn.jsdelivr.net/gh/xiangli-bjtu/Image-hosting-site/img/9.PNG" alt="9"></p><p>对于应用于计算机视觉 (Computer Vision, CV) 领域的具有卷积层的模型，由于卷积层后的数据大小增加，通常最佳的分割点在模型的中部；而对于通常只有全连接层和激活层的网络模型（主要应用在语音识别（Automatic Speech Recognition, ASR）和自然语言处理领域(Natural Language Process, NLP)）而言，在模型的开始部分或者结尾部分进行分割往往更好一点。可以看出，最佳分割点随着模型的不同而变化着。</p><p>基于不同DNN结构的应用程序的最佳分区点的变化表明：需要一种系统能够智能地选择划分DNN的最佳点以优化端到端延迟或移动设备能量消耗，并利用云服务器和设备GPU分配相应的计算操作。这也引出了下一章这篇文章的核心工作。</p><h1 id="5-Neurosurgeon"><a href="#5-Neurosurgeon" class="headerlink" title="5. Neurosurgeon"></a>5. Neurosurgeon</h1><p>对于一个DNN模型，影响最佳的分割点位置的因素主要有两种：一种是静态的因素，例如模型的结构；一种是动态的因素，即使对于相同的DNN架构，诸如无线网络状态、数据中心负载和设备剩余可用的电量等的动态因素也会影响最佳分区点。</p><p>基于以上的因素，作者为此提出了智能DNN分区引擎Neurosurgeon的设计，由部署阶段和运行时系统组成。</p><p><img src="https://cdn.jsdelivr.net/gh/xiangli-bjtu/Image-hosting-site/img/10.PNG" alt="10"></p><ul><li><strong>部署阶段</strong>：描述移动设备和服务器，以生成DNN常用的各种层类型的性能预测模型，需要注意的是这和应用程序无关的，只需要针对给定的移动和服务器平台进行一次。这组预测模型存储在移动设备上，随后用于预测每层的延迟和能量成本</li><li><strong>运行阶段</strong> ： 在移动设备上执行基于DNN的智能应用程序期间，Neurosuron会动态确定DNN的最佳分区点。 步骤如下：<ol><li>分析并提取DNN架构的图层类型和配置；</li><li>系统使用已存的层性能预测模型来估计在移动和云上执行每一层的延迟和能量消耗；</li><li>通过这些预测，结合当前的无线连接带宽和数据中心负载水平，Neurosurgeon选择最佳分区点，优化最佳端到端延迟或最佳移动能耗；</li><li>执行DNN，在移动和云之间进行分区工作。</li></ol></li></ul><h1 id="6-Evaluation"><a href="#6-Evaluation" class="headerlink" title="6. Evaluation"></a>6. Evaluation</h1><p>实验结果表明，相比于目前使用仅使用云服务器的方法，Neurosurgeon能够将应用的延迟时间平均降低了3.1倍（最高能达到40.7倍）。</p><p>在电量消耗方面，相比于现有方法，Neurosurgeon能够使得移动设备的电量消耗量平均降低至59.5%，最高能降低至94.7%。</p><p>下图展示了Neurosurgeon随着网络环境的变化（即LTE带宽变化）自适应进行分割和优化的结果（下图中的蓝色实线部分），可以看出比起现有方法（下图中的红色虚线部分）能够大幅度地降低延迟时间。</p><p><img src="https://cdn.jsdelivr.net/gh/xiangli-bjtu/Image-hosting-site/img/11.PNG"></p><p>Neurosurgeon也会与云服务器保持周期性的通讯，以获得其数据中心的负载情况。当服务器的数据中心负载较大时，它会减少往服务器上传输的数据量而增加移动设备本地的计算量。总之，Neurosurgeon能够根据服务器的负载情况作出适当的调整已达到最低的系统延迟时间。</p><p><img src="https://cdn.jsdelivr.net/gh/xiangli-bjtu/Image-hosting-site/img/12.PNG" alt="12"></p><p>随着连接网络质量的变差，Neurosurgeon会让移动设备承担更多的计算量，此时云服务器上数据中心的吞吐量将增加：较现有方法，连接LTE网络的情况下数据中心的吞吐量增加至1.43倍，而3G网络条件下则增加至2.36倍。此外还可以观察到，随着带GPU的移动设备百分比增加，Neurosurgeon增加了从云端到移动设备端的计算，导致更高的数据中心吞吐量改进。</p><p><img src="https://cdn.jsdelivr.net/gh/xiangli-bjtu/Image-hosting-site/img/13.PNG"></p><h1 id="个人体会"><a href="#个人体会" class="headerlink" title="个人体会"></a>个人体会</h1><p>这个文章更多是一个偏实验性质的论文，但有着很好的指导意义。</p><ol><li><p>不少和MEC相关的综述文章，对于可分割计算任务，给出的是如下图这样很抽象的模型描述，这篇文章把计算任务具体到以DNN为核心的有关运算，能帮助理解这些抽象模型，实际上这也是边缘应用中非常普遍的计算任务之一（许多需要边缘计算的领域，需要运行神经网络为基础的应用程序）。</p></li><li><p>作者给出了详细的实验设备、DNN框架、经典DNN模型的指导，应该来讲这篇论文的可复现的程度是很高的</p></li><li><p>作者指出这种DNN为核心的计算任务，应该在移动端和边缘服务器上联合计算。对于计算量的划分，会受到DNN模型结构这一静态因素，和诸如无线网络状态、数据中心负载和设备剩余可用的电量等动态因素影响。对于动态因素在本文里多是以实验仿真去评估，作者实际并没有做很深入的数学上的分析。</p></li><li><p>这类DNN为核心的计算任务，尤其是其中视觉有关的DNN模型。在工业场景下应该会存在更大的应用，如：车间摄像头实时监控流水线的设备运作画面、无人机航拍城市交通等，并通过无线网络上传画面配合边缘服务器联合计算。这类工业场景中的无线网络不能总保持良好状态，会影响计算结果的实时性（论文中指端到端时延，是否可以考虑引入信息年龄AoI的概念？）</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>边缘计算</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《CSAPP》读书笔记（2）：信息的表示和处理</title>
    <link href="/2019/11/28/%E3%80%8ACSAPP%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89%EF%BC%9A%E4%BF%A1%E6%81%AF%E7%9A%84%E8%A1%A8%E7%A4%BA%E5%92%8C%E5%A4%84%E7%90%86/"/>
    <url>/2019/11/28/%E3%80%8ACSAPP%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89%EF%BC%9A%E4%BF%A1%E6%81%AF%E7%9A%84%E8%A1%A8%E7%A4%BA%E5%92%8C%E5%A4%84%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h1 id="信息存储"><a href="#信息存储" class="headerlink" title="信息存储"></a>信息存储</h1><h2 id="字节、计算机进制"><a href="#字节、计算机进制" class="headerlink" title="字节、计算机进制"></a>字节、计算机进制</h2><p>现代计算机是采取二进制来表示信息的，一个0-1状态为一个<strong>比特</strong>。更为实用的单位是连续8位的块即一个<strong>字节</strong>。计算机程序将内存视为一个非常大的字节数组，内存中的每个字节由一个唯一的数字表示，称为它的<strong>地址</strong>。所有地址的集合称为<strong>虚拟地址空间</strong></p><p>信息采取0-1bit的比特串来表示是很麻烦的，更为通用的表示是采取<strong>16进制</strong>。</p><p>对于较大数值的进制转化可以借助软件工具来实现（如系统自带的科学计算器）</p><h2 id="字长"><a href="#字长" class="headerlink" title="字长"></a>字长</h2><p>每台计算机都有一个字长，也就是平常所谓的32位、64位机器。它决定着<strong>虚拟地址空间的大小（虚拟内存的字节总数）</strong>，对于字长为$W$的计算机，其虚拟地址范围为：$0~2^W-1$</p><p>对于程序是“32位程序”或“64位程序”，<strong>针对该程序是如何编译的</strong>，而不是运行机器的类型。</p><p>以C语言为例，其不同的数据类型占据内存空间的字节数目也不同</p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/C%20data%20type.png" style="zoom:67%;" /><h2 id="寻址和字节顺序"><a href="#寻址和字节顺序" class="headerlink" title="寻址和字节顺序"></a>寻址和字节顺序</h2><p>对于跨越多个字节的对象，需要建立的规则就是：这个对象的地址是什么，以及在内存中如何排列组成对象的这些字节？</p><ul><li>几乎所有计算机都是以该<strong>对象所占据若干字节中最小的地址，作为对象的地址</strong></li><li>接下来对于对象的存储顺序，主要有两种规则的排列：<ul><li><strong>小端法</strong>（little endian）：大多数Intel兼容机采用的方法，对象的最低有效字节放在内存的低地址端</li><li><strong>大端法</strong>（big endian）：IBM 和Oracle的机器，对象的最低有效字节放在内存的低地址端</li></ul></li></ul><img src="C:\Users\XiangLi\Documents\xiangli-bjtu.github.io\source\_posts\《CSAPP》读书笔记（2）：信息的表示和处理\bitorder.png" style="zoom: 67%;" /><h2 id="字符的表示"><a href="#字符的表示" class="headerlink" title="字符的表示"></a>字符的表示</h2><p>C语言中的字符串被编码为以<strong>NULL字符结尾</strong>的字符串数组，因此对于字符串’abcde’虽然看起来只有5个字符，但在C语言表示下其实际长度为6.</p><p>对于英文文本（字符数组）的表示方法，采用的是<strong>ASCII码</strong>表示，文本数据应具备更强的平台独立性。对于更为复杂的其他语言字符表示，<a href="https://www.bilibili.com/video/av23469929?from=search&seid=3003390791592500042">这个视频</a>是个很好的说明：</p><h2 id="布尔代数"><a href="#布尔代数" class="headerlink" title="布尔代数"></a>布尔代数</h2><p>英国数学家乔治布尔所创立的逻辑体系，也是现代计算机的基础之一；香农是第一个把布尔运算和数字电路联系起来的人（1937年的硕士论文）。</p><p>现在计算机的编程语言都支持布尔运算，以C语言为例，包括了位级运算和逻辑运算（这也是初学者容易混淆的几个运算符号）</p><ul><li><code>&amp;</code>，<code>|</code>，<code>~</code>：按位进行布尔运算，位运算的一个重要用途是实现<strong>掩码操作</strong></li><li><code>&amp;&amp;</code>，<code>||</code>，<code>！</code>：逻辑运算符，支持<strong>短路特性</strong></li></ul><h2 id="移位运算"><a href="#移位运算" class="headerlink" title="移位运算"></a>移位运算</h2><p>C语言中包括三种移位操作，三者实现如下：</p><ul><li><strong>左移</strong>（&lt;&lt;）：移出去的位丢弃，空缺位用 0 填充</li><li>右移（&gt;&gt;）<ul><li><strong>逻辑右移</strong>：移出去的位丢弃，空缺位用 0 填充；</li><li><strong>算术右移</strong>：移出去的位丢弃，空缺位用符号位（最高位）来填充。</li></ul></li></ul><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/1.PNG"></p><p><strong>几乎所有的编译器和机器组合，对于有符号数使用算术右移；而对于无符号数，右移一定是逻辑右移</strong></p><h1 id="整数的表示"><a href="#整数的表示" class="headerlink" title="整数的表示"></a>整数的表示</h1><p>C语言支持多种整型数据，以64位机器为例给出了每种数据类型的表示范围</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/C_data_range.PNG"></p><p>可以看到C语言为每种整型数据类型支持<strong>有符号（signed）</strong>和<strong>无符号（unsigned）</strong>两个版本，常量默认是有符号版本。有符号数的取值范围是不对称的，负数的范围比正数范围大1。</p><h2 id="无符号数的编码"><a href="#无符号数的编码" class="headerlink" title="无符号数的编码"></a>无符号数的编码</h2><p>假设一个整型数类型为w位，我们可以将它的位向量写成x，可以得到如下的映射关系B2Uw（Binary to Unsigned）表示将w位的二进制转化为无符号数</p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/B2U.PNG" style="zoom:67%;" /><h2 id="有符号数的编码"><a href="#有符号数的编码" class="headerlink" title="有符号数的编码"></a>有符号数的编码</h2><p>有符号数有很多不同的编码方式，比如<strong>补码（two’s complement）</strong>、<strong>反码（one’s complement）</strong>和<strong>原码（sign-magnitude）</strong>。其中最常见的是补码编码，C语言标准虽然没有要求要用何种形式的编码来表示有符号整数，但是<strong>几乎所有机器都会使用补码编码。</strong></p><p>同样可以定义映射关系B2Tw（Binary to Two’s complement）表示将w位的二进制转化为补码编码的有符号数</p><center><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/B2T.PNG" style="zoom:67%;" /></center><p>补码编码为最高位当作符号位，并赋予负权重。我们可以看出补码表示的两点性质</p><ul><li><p>补码编码的范围是不对称的，这是因为通过设置符号位，将一半的位模式表示为负数，将另一半的位模式表示为非负数，而0是非负数，所以负数就比正数多1个</p></li><li><p>-1的补码表示法，和同等字节大小的无符号表示最大值有相同的位模式</p></li></ul><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/v2-d5f671dada9952846dabfe60cbe859f5_1440w.jpg" alt="img"></p><p>上图提供了一些比较重要的数字及其编码，C库中的文件<code>&lt;limits.h&gt;</code>定义了一组常量，来限定编译器运行的这台机器的不同整型数据类型的取值范围，比如它定义了常量<code>INT_MAX</code>、<code>INT_MIN</code>和<code>UINT_MAX</code>，就分别对应上面推导的最大值和最小值。</p><p><em>补充：<a href="https://segmentfault.com/a/1190000021511009">一文读懂原码、反码与补码</a></em></p><p><em>原码表示和反码表示都有一个共同<strong>特点：对于数字0有两种不同的编码方式</strong>，这也是在计算机中不推荐使用这两者表示有符号数的原因，因为会造成浪费。</em></p><h2 id="有符号数和无符号数之间的转换（同字长类型转换）"><a href="#有符号数和无符号数之间的转换（同字长类型转换）" class="headerlink" title="有符号数和无符号数之间的转换（同字长类型转换）"></a>有符号数和无符号数之间的转换（同字长类型转换）</h2><p>C语言可以在各种不同的数字类型之间做强制类型转换，它的具体实现要从位级角度来看，它保持位模式不变，只是改变了解释这些位的方式，即相同位模式下由于不同的映射关系带来数值的差异。</p><p>根据上文的映射公式，可以进行如下的推导，得到转换关系如下：</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/TC_Un_convert.PNG"></p><ul><li>对于大于0的补码，符号位并没有使用，所以它能得到有无符号数相同的值；对于小于0的补码，由于符号位导致数值少了2^w，需要加上，这就使得小于0的有符号数转换为补码时，数值发生了发生跳转，一下变得很大。</li></ul><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/v2-f33fb7859f18848379bf27e11cd517e5_1440w.jpg" alt="img"></p><ul><li>当无符号数小于补码表示最大值，它还能保证最高有效位为0，这和补码表示正数时相同；而大于该最大值，由于它的最高有效位为1，使得它的值相对补码大了2^w，因此需要减去2^w，这就使得大于补码表示最大值得无符号数转化为补码时会发生跳转，一下变得很小。</li></ul><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/v2-2abbadf32c7bd2ba571bdb976c09ad05_1440w.jpg" alt="img"></p><p><strong>为什么需要了解二者的转换关系：</strong></p><p>在C语言中，当一个有符号数和一个无符号数进行计算时，会<strong>隐式地将有符号数转化为无符号数</strong>。当进行逻辑判断时，可能会导致错误或漏洞，因此建议<strong>绝不使用无符号数</strong>。</p><center><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/CSAPP_post2_ex.PNG" style="zoom:50%;" /></center><h2 id="不同字长的类型转换"><a href="#不同字长的类型转换" class="headerlink" title="不同字长的类型转换"></a>不同字长的类型转换</h2><p>在不同字长的整数之间进行类型转换，要保持在数据类型范围内的数值是不变的。以下有两种情况：从较短字长的数据类型转换到较长字长的数据类型，比如short到int，就需要进行<strong>扩展位</strong>；从较长字长的数据类型转换到较短字长的数据类型，比如int到short，就需要<strong>截断位</strong>。</p><p><strong>扩展</strong></p><ul><li>将一个无符号数进行扩展，直接在其前面填充零即可，根据无符号数的定义不会改变其数值大小，这称为<strong>零扩展</strong></li><li>与无符号数相比，把有符号数转化为一个更大的数据类型需要进行<strong>符号位扩展</strong>。当符号位为0/1，此时扩展的数位进行补0/1</li></ul><p><strong>截断</strong></p><p>截断位时，数值通常会发生变化。</p><ul><li>对于w位无符号整数，保留$w’$，只需丢弃$w’$之前的位即可。截断操作相当于二进制取模运算</li><li>截断有符号数得操作，需要先将二进制数转换成无符号数，通过上面的公式进行截断后，再转换成补码</li></ul><h1 id="整数的运算"><a href="#整数的运算" class="headerlink" title="整数的运算"></a>整数的运算</h1><p>计算机内部通过二进制进行整数运算，由于有限位以及编码方式的限制，可能会导致计算机计算的结果和真实结果之间存在差异，也就发生了<strong>溢出</strong>（完整的计算结果不能放到数据类型的字长限制中）</p><h2 id="加法"><a href="#加法" class="headerlink" title="加法"></a>加法</h2><h3 id="无符号数加法"><a href="#无符号数加法" class="headerlink" title="无符号数加法"></a>无符号数加法</h3><p>w位的无符号数，其表示范围在[0,$2^w$），当计算结果超过最大范围（即超过最大的位数），计算机会直接去掉w+1之后的位，相当于是计算结果对$2^w$进行了取模，所以该方法称为<strong>模数加法</strong>。在C语言的运行中这种情况并不会产生报错，如果我们希望判定计算结果是否溢出，可以使用以下的代码：</p><p><strong>判定溢出</strong>：可以看出<strong>两无符号数相加发生溢出时，返回的结果小于二者中任一元素</strong>。</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/overflow1.PNG"></p><h3 id="有符号数加法"><a href="#有符号数加法" class="headerlink" title="有符号数加法"></a>有符号数加法</h3><p>使用补码的一个优势在于：补码加法可以使用和无符号数加法相同的硬件，相同的算法，就得到有符号数的加法。所以大多数计算机用<strong>相同的机器指令来执行补码和无符号数加法</strong>。</p><p>与无符号加法不同的是，有符号数加法分为<strong>正溢出和负溢出</strong>。</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/overflow2.PNG"></p><p><strong>判定溢出</strong>：</p><ul><li>两正数相加结果为负，发生正溢出</li><li>两负数相加结果为正，发生负溢出</li></ul><h2 id="减法"><a href="#减法" class="headerlink" title="减法"></a>减法</h2><p><strong>加法逆元</strong>：每个元素都有一个加法逆元，当与自己的加法逆元相加时，其结果得到0。</p><ul><li>无符号数的加法逆元：</li></ul><p>由于无符号数的数值表示范围不包括负数，因此无符号数的加法逆元和数学上的相反数数值不同。为得到w位无符号数x的无符号表示加法逆元，需要利用溢出效应，如下所示：</p><center><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/add_inverse1.PNG" style="zoom:80%;" /></center><ul><li>无符号数的加法逆元：</li></ul><p>大多数无符号数的逆元是直接对其取相反数即可。需要注意的是由于无符号数表示范围为非对称的区间，因此对于最小值的逆元需要使用负溢出来实现。根据下述计算公式，<strong>补码最小值的逆元是其本身。</strong></p><center><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/add_inverse2.PNG" style="zoom:67%;" /></center><p>根据以上的定义，<strong>计算机中实现减法的实现本质上还是加法运算，是通过加上减数的加法逆元。</strong></p><h2 id="乘法"><a href="#乘法" class="headerlink" title="乘法"></a>乘法</h2><p>两个w位的数相乘实际计算结果最大为2w位，但在C语言中会截取2w位的低w位作为结果（也就是上文提的截断操作进行取模运算）</p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/us_mul.PNG" style="zoom:67%;" /><p>无论是无符号数和有符号数，乘法的位级运算都是一样的。只不过补码乘法比无符号数乘法多一步，由于截断操作会得到无符号数（计算结果为正），此时就要将无符号数转化为对应的补码。</p><p>从下面的表格可以看到，相同位模式的无符号数和有符号数乘法，在按照上述乘法的定义进行操作后，虽然完整结果的位级表示可能不同，但保证了阶段操作后位模式一致。<a href="https://www.bilibili.com/video/BV1Ff4y1q7Kf">关于这部分的数学证明</a></p><img src="C:\Users\XiangLi\Documents\xiangli-bjtu.github.io\source\_posts\《CSAPP》读书笔记（2）：信息的表示和处理\mul_ex.PNG" style="zoom:67%;" /><p>大多数机器中，整数乘法指令的执行通常需要几十个时钟周期，所以计算机通常会用移位和加减法的组合来代替。</p><ul><li><strong>乘上2幂</strong></li></ul><p>首先我们讨论乘上2幂的特殊情况，在允许的w位表示范围内，乘上2的k此幂等于左移k位，如果超过了表示范围，就会发生溢出。</p><ul><li><strong>乘上任意数</strong></li></ul><p>对于任意整数k，我们可以先对计算关于2幂次的展开。如14=8+4+2。由此就将一个乘法运算转化为了多个移位操作和加法操作的组合。</p><h2 id="除法"><a href="#除法" class="headerlink" title="除法"></a>除法</h2><p><strong>除以2幂</strong></p><p>同理对于除法我们使用右移，正如前面关于移位操作提到的，要注意<strong>对于有符号数使用算术右移；而对于无符号数，右移一定是逻辑右移</strong></p><p>在除法运算中，比较麻烦的是出现除不尽的情况，此时就需要舍入，我们希望<strong>计算结果都是向0舍入</strong>的。</p><ul><li><strong>无符号数舍入</strong></li></ul><p>我们引入如下的变量代表无符号数x逻辑右移k位、右移结果再进行左移、低k位的位向量。</p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/image-20210221114627920.png" alt="image-20210221114627920" style="zoom:67%;" /><p>因此对于原始的无符号数x，其对2的k此幂进行除法的结果并进行向下取整可以表示：<strong>可见无符号数的除法运算直接进行右移操作即可，会自动完成向下取整。</strong></p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/div_2.PNG" style="zoom:67%;" /><ul><li><strong>补码除法</strong></li></ul><p>对于数值为非负数的补码其规则和无符号数一致；但是对于数值为负数的补码，我们需要先加上一个<strong>偏移量</strong>，使其满足向0舍入的预期。下面通过一个例子说明：</p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/div_3.PNG" style="zoom:67%;" /><p>可以看到-12340除以16，如果直接取移位后的结果为-772，不符合整数除法向0舍入的原则-771。因此负数值的符号数在进行除法的右移k位操作前，要先加上一个修正值。<u>修正值的计算为1左移k位再减1</u></p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/div_bias.PNG" style="zoom:67%;" /><p>可以看出，在偏置之后，在负结果舍入时，移位运算的结果将会是我们期望得到的</p><p><u>和乘法不同，对于任意的整数除法我们不能采取将其拆分为若干2的幂次加和，再分别相除。</u></p><h1 id="浮点数"><a href="#浮点数" class="headerlink" title="浮点数"></a>浮点数</h1><h2 id="IEEE浮点表示方法"><a href="#IEEE浮点表示方法" class="headerlink" title="IEEE浮点表示方法"></a>IEEE浮点表示方法</h2><p>IEEE浮点表示涉及三个部分</p><ul><li><strong>符号（Sign）s：</strong>用来确定V的正负性，当s=0时表示正数，s=1时表示负数。用一个单独的符号位直接进行编码。</li><li><strong>尾数（Significand）M：</strong> 是一个二进制小数，通常介于1和2之间的小数。使用k位二进制进行编码的小数。</li><li><strong>阶码（Exponent）E：</strong>对浮点数进行加权。使用n位进行编码的正数</li></ul><center><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/float.PNG" style="zoom:67%;" /></center><p>不同精度浮点数的区别在于尾数和阶码的长度不同：32位单精度浮点数具有8位的阶码和23位的尾数长度，而64位双精度浮点数则为11位的阶码和52位的尾数长度）</p><p>我们可以根据<strong>阶码</strong>的不同取值，将浮点数的类型分成三种情况：</p><ul><li><strong>规格化的值</strong></li></ul><p>需要注意阶码部分的实际取值并不是阶码对应比特串的数值，而是要减去一个偏置（取决于阶码字段的长度），这么做的目的使得阶码的数值能重新投影到正负值，并且能够和非规格化数据进行平滑。</p><center><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/float_type1.PNG" style="zoom:67%;" /></center><p>而对于尾数部分M的取值，将其设定为介于1和2之间的小数，因此尾数字段表示小数点之后的部分，如下的公式</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/float_type11.PNG"></p><p>结合以上的定义，我们就能带入浮点数计算公式得到规格化数值</p><ul><li><strong>非规格化的值</strong></li></ul><p>阶码字段全为0时，表示非规格化的数值。非规格化数的用途在于：</p><ol><li>提供了正负0的表示</li><li>趋近于0的数的表示，这里需要注意，此时对于阶码和尾数的计算方式和规格化数据有所不同</li></ol><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/float_type2.PNG" style="zoom:67%;" /><ul><li><strong>特殊值</strong></li></ul><p>特殊值包括正负无穷大以及NaN（Not a Number）</p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/float_type3.PNG" style="zoom:67%;" /><p><strong>示例：整数表示为浮点数</strong></p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/int2float_ex.PNG" style="zoom: 67%;" /><h2 id="浮点数的舍入"><a href="#浮点数的舍入" class="headerlink" title="浮点数的舍入"></a>浮点数的舍入</h2><p>由于表示位数的限制，浮点数运算只能近似的表示真实的实数运算。因此我们需要一种’’最接近真实结果’的舍入方法。</p><p>IEEE定义了4种舍入格式</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/v2-098cc0a1bd3c8a46fae91bfc9a110071_1440w.jpg" alt="img"></p><p>比较特殊的是<strong>向偶数舍入</strong>，其舍入结果遵循：<strong>如果处于中间值，就朝着令最后一个有效位为偶数来舍入；否则朝着最近的值舍入</strong>。比如1.40，由于靠近1就朝1舍入；1.6靠近2就朝2舍入；1.50位于十进制的中间值，就朝着偶数舍入，所以为2。</p><blockquote><p>向偶数舍入的意义：如果对一系列值进行向上舍入，则舍入后的平均值会比真实值更大；使用向下舍入，则舍入后的平均值会比真实值更小。通过向偶数舍入，每个值就有50%概率变大、50%概率变小，使得总的统计量保持较为稳定。</p></blockquote><p>当需要舍入到小数点后的情况，以上的原则依然适用</p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/float_round.PNG" style="zoom:67%;" /><h2 id="浮点数的计算"><a href="#浮点数的计算" class="headerlink" title="浮点数的计算"></a>浮点数的计算</h2><p>浮点数运算由于计算结果溢出或舍入的操作，不具备结合律，比如下面的几个典型例子</p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/float_oprate.PNG" style="zoom:67%;" /><p><strong>建议：</strong>对于从事科学计算的程序来说，需要考虑好清楚数值的范围，如果计算的数值范围变化很大，需要重新结合或改变运算顺序，避免由于溢出或舍入出现计算问题。</p><p><strong>C语言中的浮点数</strong></p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/float_in_C.PNG" style="zoom:67%;" />]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>计算机基础</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《CSAPP》读书笔记（1）：计算机系统漫游</title>
    <link href="/2019/11/11/%E3%80%8ACSAPP%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89%EF%BC%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%BC%AB%E6%B8%B8/"/>
    <url>/2019/11/11/%E3%80%8ACSAPP%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89%EF%BC%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%BC%AB%E6%B8%B8/</url>
    
    <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>这个系列是对于《Computer Systems: A Programmer’s Perspective》（中译名为《深入理解计算机系统》，我觉得更直接的名字应该是《以程序员的视角理解计算机系统》）的读书笔记，作为计算机领域的经典书籍，每一名计算机行业的从业人员都应该去研读一下这本著作。</p><p>在b站有搬运的教学视频：<a href="https://www.bilibili.com/video/BV1iW411d7hd">2015 CMU 15-213 CSAPP 深入理解计算机系统 课程视频</a>。除了观看视频，还有6个Lab也是值得去完成的，能加深你对整本书内容的理解。Lab的handout和start code可以在<a href="https://link.zhihu.com/?target=http://csapp.cs.cmu.edu/3e/labs.html">CS:APP3e, Bryant and O’Hallaron</a> 这里找到。</p><p>全书一共12章，第一章为对整本书的概述，主要以hello world程序的生命周期为线索，介绍了计算机系统的主要概念。剩余11章可分为3个部分：</p><ul><li>2—6：程序结构和执行</li><li>7—9：在系统上运行程序</li><li>10—12：程序间的交互和通信</li></ul><p>本系列文章的图片主要截取自教材以及b站UP主<a href="https://space.bilibili.com/354767108?spm_id_from=333.788.b_765f7570696e666f.1">九曲阑干</a>的视频，以及<a href="https://zhuanlan.zhihu.com/p/103476182">知乎：[读书笔记]CSAPP深入理解计算机系统</a></p><h1 id="一个hello-world程序的生命周期"><a href="#一个hello-world程序的生命周期" class="headerlink" title="一个hello world程序的生命周期"></a>一个hello world程序的生命周期</h1><p>hello world程序作为大部分接触编程的人的第一个程序，其C语言的表示如下：</p><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;stdio.h&gt;</span></span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span>&#123;    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;hello world\n&quot;</span>);    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;&#125;</code></pre><p>这段代码需要保存在一个文件中，称为源文件（hello.c），这是这段程序生命周期的开始。</p><p>现代计算机只知道0和1的二进制数，为理解这段文本到底是什么意思，计算机系统会使用ASCII标准来表示这些文本，简单来说就是给每个字符都指定一个唯一的单字节大小的编号，然后将文本中的字符都根据ASCII标准替换成对应的编号后，就转换成了字节序列，即<strong>源文件是以字节序列的形式保存在文件中</strong>。对于这样只有ASCII字符构成的文件称为<strong>文本文件</strong>，所有其他文件都称为<strong>二进制文件</strong>。</p><p>使用高级的C语言编写这段程序是为了方便人理解，但是对于计算机来说太过于复杂了，它只能执行指令集中包含的指令。为了能够在系统中运行这段程序，源文件到计算机可执行的目标程序需要经历以下4个阶段：<img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/1.png"></p><ul><li><strong>预处理</strong>：处理源程序中以<code>#</code>开头的部分，并对源程序进行修改，比如将<code>#include &lt;stdio.h&gt;</code>替换成头文件<code>stdio.h</code>中的内容。</li><li><strong>编译</strong>：编译器将C语言下预处理后的<code>hello.i</code>翻译成汇编语言的<code>hello.s</code>。 这样做的好处在于：<ul><li>通过为不同语言不同系统上配置不同的编译器，能够提供通用的汇编语言处理结果</li><li>对于相同的语言能兼容不同的操作系统，</li><li>同一个系统上，通过安装不同语言的编译器，也能运行不同语言写的程序了。</li></ul></li></ul><p>汇编的过程包括词法分析、语义分析、中间代码优化等细节，汇编语言相对C语言这类高级语言也更加低级且与计算机的底层硬件密切相关。本书不会过多的展开，对这部分感兴趣的可以在读完本书后去学习编译原理</p><ul><li><strong>汇编</strong>：将汇编程序翻译成<strong>机器语言指令</strong>，并将其打包成一种叫<strong>可重定位目标程序</strong>(relocatable object program)的二进制文件。对于微软编译器（内嵌在 Visual C++ 或者 Visual Studio 中），目标文件的后缀为<code>.obj</code></li><li><strong>链接</strong>：链接器将各个.o文件合并成<strong>可执行文件</strong>。链接器使得分离编译成为可能。在编写大型程序时，通常会使用到各种函数库，但是我们代码中并没有这些函数的具体实现，所以就需要在链接阶段将该函数的具体实现合并，最终得到可执行目标文件。</li></ul><h1 id="计算机的硬件组成"><a href="#计算机的硬件组成" class="headerlink" title="计算机的硬件组成"></a>计算机的硬件组成</h1><p>经历了上一步，可执行目标文件已经在磁盘上了。那么如何运行这个程序呢，以Linux系统为例：</p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/image-20210123112721494.png" alt="image-20210123112721494" style="zoom:67%;" /><p>接下来看看在运行程序时计算机系统内部发生了什么，不过在此之前我们需要了解计算机系统的硬件构成，如下图：</p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/2.png" style="zoom: 50%;" /><ol><li>**总线(buses)**：通常总线被设计成传送定长的字节块，也就是字。字中的字节数(字长word size)，是一个基本的系统参数，大多数机器为4个字节(32位)或8个字节(64位)</li><li>**I/O设备(I/O devices)**：每个I/O设备都通过一个控制器(controller)或者适配器(adapter)与I/O总线相连接。控制器和适配器的区别主要在于其封装方式：控制器是置于I/O设备本身的或主板上的芯片组，而适配器则是一块插在主板插槽上的卡</li><li>**主存(main memory)**：主存即内存，是一个CPU能直接寻址的临时存储设备，在处理器执行程序时用来存放程序和程序处理的数据。物理上，主存由一组DRAM组成。逻辑上，存储器是一个线性的字节数组，每一个字节都有其唯一的地址(数组索引)，这些地址均从零开始。</li><li>**处理器(processor)**：一个CPU由若干部分组成：<ul><li>寄存器：通常为8位寄存器，用来保存一个字节的数据。CPU中有若干寄存器，每个寄存器都有唯一的地址，用来保存CPU中临时运算结果。其中有两个寄存器比较特殊：</li><li>指令地址寄存器：用来保存当前指令在内存中的地址，每次执行完一条指令后，会对该寄存器的值进行修改，指向下一条指令的地址。</li><li>指令寄存器：用来保存当前从主存中获取的，需要执行的指令。</li><li>ALU：算术逻辑单元，主要用来处理CPU中的数学和逻辑运算。它包含两个二进制输入，以及一个操作码输入，用来决定对两个输入进行的算数逻辑操作。然后会输出对应的运算结果，以及具有各种标志位，比如结果是否为0、结果是否为负数等等。</li><li>控制单元：是一系列门控电路，通过门控电路来判断指令寄存器中保存的指令内容，然后调整控制主存和寄存器的读写数据和地址，以及使用ALU进行运算。我的理解就是一系列门控电路，然后根据你程序的指令来调控CPU中的各种资源。</li></ul></li></ol><p>CPU中执行指令的过程：首先根据指令地址寄存器从内存中获取对应地址的数据，然后将其保存在指令寄存器中，然后控制单元会对指令内容进行判断，并调用寄存器、ALU等执行指令内容，然后更新指令地址寄存器，使其指向下一个要执行的指令地址。</p><p><strong>hello程序的执行过程</strong></p><p>可以看到即使这么一个简单的程序都需要在计算机系统内部经历复杂的交互。</p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/3.png" style="zoom: 50%;" /><h1 id="高速缓存"><a href="#高速缓存" class="headerlink" title="高速缓存"></a>高速缓存</h1><p>如上图的程序执行过程所示，hello程序最初存放在磁盘上，当程序加载时，被复制到内存中，当CPU运行时，指令又被复制到CPU中。这些过程会花费大量时间将代码和数据进行复制，减缓了程序“真正”的工作，程序设计的一个主要任务就是要减少信息的“搬运时间”，实现程序运行的加速。</p><ul><li>关于存储设备的两条准则是：<strong>较大的存储设备比较小的存储设备运行得慢，而高速设备的造价远高于同类的低速设备</strong>。CPU内部的寄存器上处理器读取数据的速度要比主存快很多，并且这种差距还在持续增大。针对二者间的差距，在中间引入了**高速缓存（cache)**，用来暂时保存处理器近期可能会需要的数据，使得大部分的内存操作都能在高速缓存内完成，就能极大提高系统速度了</li><li>在单处理器系统中，一般含有二级缓存，最小的L1高速缓存速度几乎和访问存储器相当，大一些的L2高速缓存通过特殊总线连接到处理器，虽然比L1高速缓存慢，但是还是比直接访问主存来的快。在多核处理器中，还有一个L3高速缓存，用来共享多个核之间的数据。一般利用了高速缓存的程序会比没有使用高速缓存的程序的性能提高一个数量级。</li></ul><p>高速缓存的思想其实不仅仅能应用于CPU中，其实对其进行扩展，就能将计算机系统中的存储设备都组织成一个存储器层次结构，如下图所示</p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/4.jpg" style="zoom: 50%;" /><p>存储器层次结构的主要思想是将上一层的存储器作为下一层存储器的高速缓存。程序员可以利用对整个存储器层次结构的理解来提高程序性能。</p><h1 id="操作系统"><a href="#操作系统" class="headerlink" title="操作系统"></a>操作系统</h1><p>通过hello程序的运行细节，我们可以看到无论是shell程序还是hello程序都没有直接操控计算机硬件设备，<strong>真正操控硬件的是操作系统</strong>，它可以看成是应用程序和硬件之间的一层特殊软件。这么做的好处在于：</p><ul><li>防止硬件被失控的应用程序滥用</li><li>给程序员提供硬件的抽象，为了这一目的，操作系统主要提供了几层的抽象：<strong>进程(processes)**、</strong>虚拟内存(Virtual Memory)<strong>、</strong>文件(Files)**</li></ul><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/Process.png" style="zoom: 50%;" /><p><strong>进程</strong></p><p>为了方便对运行程序时所需的硬件进行操作，操作系统对正在运行的程序提供了一种抽象：进程。一个系统上可以同时运行多个进程，操作系统为每个进程提供了一直错觉，好像各自在独占地使用硬件。这样程序员就无需考虑程序之间切换所需操作的硬件。操作系统通过交错执行若干个程序的指令，不断地在进程间进行切换来提供这种错觉，这个称为<strong>并发运行</strong>。</p><p>现代系统中，一个进程中可以并发多个线程，每条线程并行执行不同的任务，<strong>线程是操作系统能够进行运算调动的最小单位</strong>，是进程中的实际运作单位，相比于进程：1）多线程之间比多进程之间更容易共享数据。2）线程一般来说都比进程更高效。</p><p><strong>虚拟内存</strong></p><p>将多个程序的指令和数据保存在内存中，当某个程序的数据增时，可能不会保存在内存的连续地址中，这就使得代码需要对这些在内存中非连续存储的数据进行读取，会造成很大的困难。为了解决这个问题，操作系统对内存和I/O设备进行抽象（即在你电脑的物理内存不够用时把一部分硬盘空间作为内存来使用）。程序运行在从0开始的连续虚拟内存空间中，而操作系统负责将程序的虚拟内存地址投影到对应的真实物理内存中。这样使得程序员能直接对连续的空间地址进行操作，而无需考虑非连续的物理内存地址。</p><p>操作系统将进程的虚拟内存划分为多个区域，每个区域都有自己的功能，接下来自下而上介绍：</p><ul><li>程序代码和数据：对于所有进程来说，代码都是从同一固定地址开始，紧接着是全局变量相对应的数据位置。代码和数据区在进程一开始运行时就被规划了大小。</li><li>堆(Heap)：如C语言中调用<code>malloc</code>和<code>free</code>时，堆可以在运行时动态的扩展和收缩</li><li>共享库(Shared libraries)：存放像C标准库和数学库这样共享库的代码和数据的区域</li><li>栈(Stack)：编译器用它来实现函数调用。当调用一个函数时，栈增长；从一个函数返回时，栈收缩</li><li>内存虚拟存储器(Kernel virtual memory)：内核总是驻留在内存当中，是操作系统的一部分。该区域<strong>不允许</strong>应用程序读写或者直接调用其中的函数。</li></ul><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/7.png" style="zoom:50%;" /><p><strong>文件</strong></p><p>Linux的哲学是：一切皆文件。所有I/O设备都可视作文件，系统中所有的输入输出都视作读取文件的操作。</p><h1 id="网络通信"><a href="#网络通信" class="headerlink" title="网络通信"></a>网络通信</h1><p>书中这部分的例子：</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/8.png"></p><h1 id="提高系统运行"><a href="#提高系统运行" class="headerlink" title="提高系统运行"></a>提高系统运行</h1><p>首先引出了系统加速比的推导（Almdahl’s law）如下：该定律提供的一个主要观点是<strong>：</strong>要想显著加速整个系统，必须提升全系统中相当大的部分的速度。</p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/Amdahl%20law.png" style="zoom:67%;" /><p>为了实现系统加速，主要可通过以下3种途径：</p><ul><li><p>线程级并发</p></li><li><p>指令级并行</p></li><li><p>单指令、多数据并行</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>计算机基础</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Win10 Terminal + WSL 2 安装配置指南</title>
    <link href="/2019/11/02/Win10-Terminal-WSL-2-%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/"/>
    <url>/2019/11/02/Win10-Terminal-WSL-2-%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/</url>
    
    <content type="html"><![CDATA[<h1 id="Windows-Terminal-安装"><a href="#Windows-Terminal-安装" class="headerlink" title="Windows Terminal 安装"></a>Windows Terminal 安装</h1><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>众所周知，Windows系统自带的终端<code>cmd, PowerShell</code>一直遭受诟病，以傻、黑、粗闻名于世。不过微软在2019开发者大会上发布了新的终端模拟器——Windows Terminal：一个面向命令行工具和 shell（如命令提示符、PowerShell 和适用于 Linux 的 Windows 子系统 (WSL)）用户的新式终端应用程序。 它的主要功能包括多个选项卡、窗格、Unicode 和 UTF-8 字符支持、GPU 加速文本呈现引擎，你还可用它来创建你自己的主题并自定义文本、颜色、背景和快捷方式。</p><p>在介绍安装Windows Terminal之前，我们需要先对一些概念做了解：</p><p><a href="https://printempw.github.io/the-difference-between-cli-terminal-shell-tty/">命令行界面 (CLI)、终端 (Terminal)、Shell、TTY，傻傻分不清楚？</a></p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p><strong>注意：Windows Terminal 要求 Windows 10 1903 (build 18362) 及以上版本。</strong></p><p>直接在Microsoft Store 里搜索安装即可。</p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/windows-terminal-microsoft-store.png" style="zoom:67%;" /><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>默认情况下，安装后打开终端后的下拉菜单中包含 Windows PowerShell、Command Prompt 和 Azure Cloud Shell 配置文件，在打开新的选项卡时会以 PowerShell 作为默认配置文件启动。</p><p> 和 VS Code 一样，使用 JSON 文件配置相关选项。默认情况下，每个配置文件使用不同的命令行可执行程序（即对应打开的终端），但是您可以根据自己的喜好，创建任意数量的使用同一可执行程序的配置文件。</p><p>Windows Terminal 中包含两个设置文件。一个是<strong>defaults.json</strong>，可以通过按住 <code>Alt</code> 键并点击下拉菜单中的 Settings 按钮打开，这是一个不可更改的文件，其中包含 Windows Terminal 的所有默认设置。另一个是 <strong>settings.json</strong>，可以通过点击下拉菜单中的 Settings 按钮访问，您可以在其中应用所有的自定义设置。</p><p>settings.json配置文件主要包含了如下的几个部分：</p><ul><li><p><strong>全局设置</strong>：位于 settings.json 文件的最外侧，这一部分的属性都将影响整个终端窗口。主要包括：默认配置程序的GUID 或配置文件名称、终端启动大小、鼠标滚动速度等</p></li><li><p>**配置文件设置<code>&quot;profiles&quot;</code>**，<code>&quot;profiles&quot;</code> 对象分为两个部分：<code>&quot;defaults&quot;</code> 和 <code>&quot;list&quot;</code>。</p><pre><code class="hljs json">&quot;defaults&quot;:&#123;    <span class="hljs-comment">// SETTINGS TO APPLY TO ALL PROFILES</span>&#125;,&quot;list&quot;:[    <span class="hljs-comment">// PROFILE OBJECTS</span>]</code></pre><p> <code>&quot;list&quot;</code> 中是出现在 Windows 终端下拉菜单中的所以程序，你可以为其中的每个唯一的配置文件单独进行配置， 如果希望将某个设置应用于所有配置文件，则应该将其添加到 <code>&quot;defaults&quot;</code> 部分。</p><p>可以为终端设置背景图片、透明度、字体等显示。</p></li><li><p>**配色主题 <code>schemes</code>**：可以在 settings.json 文件的 <code>schemes</code> 数组中定义配色方案，一个好的的配色方案网址是 <a href="https://windowsterminalthemes.dev/">Windows Terminal Themes</a></p><p>当然，windows终端在其 defaults.json 文件中有一些预设的主题，可按住 alt 并选择设置按钮来访问该文件。 如果要在一个命令行配置文件中设置配色方案，请添加 <code>colorScheme</code> 属性，并将配色方案的 <code>name</code> 作为值。</p></li><li><p>**快捷键绑定 <code>actions</code>**：自定义快捷键。</p></li></ul><p>更多配置详情见官网文档：<a href="https://docs.microsoft.com/zh-cn/windows/terminal/">https://docs.microsoft.com/zh-cn/windows/terminal/</a></p><h2 id="Git-bash-置入-Windows-Terminal"><a href="#Git-bash-置入-Windows-Terminal" class="headerlink" title="Git-bash 置入 Windows Terminal"></a>Git-bash 置入 Windows Terminal</h2><p>我们之前在搭建hexo博客时已经安装好了git for windows。</p><p>下载一个git 的图标，地址见 <a href="https://gitforwindows.org/img/gwindows_logo.png">gwindows_logo</a>。将在下载的图标保存到任意一个文件夹</p><p>在settings.json的“profiles”部分1添加如下一段内容：</p><pre><code class="hljs json">&#123;<span class="hljs-attr">&quot;guid&quot;</span>: <span class="hljs-string">&quot;&#123;b453ae62-4e3d-5e58-b989-0a998ec441b7&#125;&quot;</span>,<span class="hljs-attr">&quot;hidden&quot;</span>: <span class="hljs-literal">false</span>,    <span class="hljs-attr">&quot;name&quot;</span>: <span class="hljs-string">&quot;git bash&quot;</span>,<span class="hljs-attr">&quot;icon&quot;</span>: <span class="hljs-string">&quot;C:\\Users\\XiangLi\\Pictures\\gwindows_logo.png&quot;</span>,<span class="hljs-attr">&quot;commandline&quot;</span>: <span class="hljs-string">&quot;D:\\Git\\bin\\bash.exe&quot;</span> &#125;</code></pre><h2 id="添加到右键菜单"><a href="#添加到右键菜单" class="headerlink" title="添加到右键菜单"></a>添加到右键菜单</h2><p>参考：<a href="https://www.cnblogs.com/jasongrass/p/12960289.html">https://www.cnblogs.com/jasongrass/p/12960289.html</a></p><h1 id="WSL2"><a href="#WSL2" class="headerlink" title="WSL2"></a>WSL2</h1><h2 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h2><p>Windows Subsystem for Linux（适用于 Linux 的 Windows 子系统）的简写。它有两个版本，WSL 1 和 WSL 2。 建议使用 WSL 2，它具有更好的整体性能。</p><ul><li><p>安装WSL2要求你的电脑运行的是 Win10 ，且版本号为 2004（内部版本19041）或更高。使用 <code>win + r</code> 输入 <code>winver</code> 可快速查看 Windows 版本。如果你的 Win10 版本号低于 2004，可使用 Windows 10 易升工具手动升级。</p></li><li><p>启用 Windows 子系统功能，使用管理员权限打开一个 PowerShell 窗口，输入以下命令后重启系统：</p></li></ul><pre><code class="hljs powershell">dism.exe /online /<span class="hljs-built_in">enable-feature</span> /featurename:Microsoft<span class="hljs-literal">-Windows</span><span class="hljs-literal">-Subsystem</span><span class="hljs-literal">-Linux</span> /all /norestart</code></pre><ul><li>由于当前Windows 默认启用的是 WSL1，还需要再启用虚拟机平台功能，在 PowerShell 中输入以下命令后再次重启系统</li></ul><pre><code class="hljs powershell">dism.exe /online /<span class="hljs-built_in">enable-feature</span> /featurename:VirtualMachinePlatform /all /norestart</code></pre><ul><li>下载<a href="https://wslstorestorage.blob.core.windows.net/wslblob/wsl_update_x64.msi">用于x64机器的WSL2 Linux内核更新程序包</a>，如果您使用的是ARM64计算机，请改为下载<a href="https://wslstorestorage.blob.core.windows.net/wslblob/wsl_update_arm64.msi">ARM64软件包</a>。如果不确定所用的机器类型，请打开“命令提示符”或“ PowerShell”并输入：<code>systeminfo | find &quot;System Type&quot;</code></li><li>在 PowerShell 中输入以下命令，将 WSL 默认版本改为 WSL2:</li></ul><pre><code class="hljs powershell">wsl -<span class="hljs-literal">-set</span><span class="hljs-literal">-default</span><span class="hljs-literal">-version</span> <span class="hljs-number">2</span></code></pre><ul><li><p>接下来在 Microsoft Store 中找一个 Linux 发行版进行安装</p></li><li><p>可以通过打开PowerShell命令行并输入命令来检查分配给已安装的每个Linux发行版的WSL版本<code>wsl -l -v</code></p><p>若要为安装的不同发行版设置为任一版本的WSL支持，请运行：</p><pre><code class="hljs powershell">wsl -<span class="hljs-literal">-set</span><span class="hljs-literal">-version</span> &lt;distribution name&gt; &lt;versionNumber&gt;</code></pre><p>确保<code>&lt;distribution name&gt;</code>用发行版的实际名称和<code>&lt;versionNumber&gt;</code>数字“ 1”或“ 2”代替。</p></li></ul><p><strong>注意</strong>：WSL默认安装在Windows的C盘，单单一个WSL不会造成C盘太大的负担，但是当你对WSL使用增多，尤其一通<code>apt-get install</code>操作后，C盘容量可能变得捉急，因此使用WSL后C盘使用容量这点需要大家注意。</p><h2 id="搭配VS-Code使用"><a href="#搭配VS-Code使用" class="headerlink" title="搭配VS Code使用"></a>搭配VS Code使用</h2><p>首先需要：</p><ul><li>安装VS Code时需要勾选环境变量添加到<code>path</code></li><li>在VS Code插件选项安装<code>Remote Development</code>，包含了<code>Remote-WSL</code>、<code>Remote-SSH</code>、<code>Remote Contains</code>3个插件</li></ul><p>VS Code和WSL的交互有两种方式：</p><ol><li><p><strong>VS Code打开</strong>：进入VS Code中按下快捷键<code>Crtl+Shift+p</code>，选择<code>Remote-WSL</code>命令，等待片刻后会打开一个连接到WSL的新窗口，此时工作区新建的文件夹就默认是在WSL中的了，也可以直接选择WSL内已存在的文件夹</p></li><li><p><strong>命令行打开</strong>：从WSL下切换到想要打开的项目, 既可以是WSL环境下的目录，也可以是Windows系统里的目录（不过要注意Windows的目录是以挂载的方式，如C盘在<code>/mnt/c</code>下面）。然后在命令行里敲<code>code .</code>，或者直接使用<code>code 文件夹</code>的方式。这样就能以Linux环境的模式打开VS Code</p></li></ol><p><strong>C/C++ 开发环境配置</strong></p><ul><li>由于默认源在国外会遇到软件更新下速度慢的情况，建议先<a href="https://zhuanlan.zhihu.com/p/61228593">更换国内源</a>，再执行以下命令在WSL中安装了编译器套件（<a href="https://zhuanlan.zhihu.com/p/113246292">关于Linux下修改文件内容的操作</a>)</li></ul><pre><code class="hljs routeros"><span class="hljs-comment"># 安装C语言编译器</span>sudo apt-<span class="hljs-builtin-name">get</span> install gcc<span class="hljs-comment"># 安装C++编译器</span>sudo apt-<span class="hljs-builtin-name">get</span> install g++</code></pre><blockquote><p>gcc 最开始的时候是 GNU C Compiler, 就是一个c编译器。但是后来因为这个项目里边集成了更多其他不同语言的编译器，GCC就代表 the GNU Compiler Collection，所以表示一堆编译器的合集。GCC已经不是当初那个c语言编译器了，更确切的说他是一个驱动程序，根据代码的后缀名来判断调用c编译器还是c++编译器 (g++)。比如你的代码后缀是*.c，他会调用c编译器还有linker去链接c的library。如果你的代码后缀是cpp, 他会调用g++编译器，当然library call也是c++版本的。</p><p>简单来将把gcc当成c语言编译器，g++当成c++语言编译器用就是了。</p></blockquote><ul><li>在VSCode中安装两个插件，这样不用配置tasks.json和luanch.json文件就可以很方便的编译并运行源代码文件</li></ul><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/image-20210126102445706.png" alt="image-20210126102445706"></p><h2 id="设置"><a href="#设置" class="headerlink" title="设置"></a>设置</h2><h3 id="文件系统互通"><a href="#文件系统互通" class="headerlink" title="文件系统互通"></a>文件系统互通</h3><p>WSL2 访问 Windows 文件系统依然通过挂载分区的方式，WSL里面访问windows文件很简单，你只需要输入<code>cd /mnt/d</code>，就是d盘了，以此类推。</p><p>相比于 WSL1，这次增加了 Windows 访问 Linux 分区的能力，可以在资源管理器中输入 <code>\\wsl$\&lt;子系统名&gt;</code> 访问对应的子系统分区，为了方便也可以在资源管理器中把 Linux 分区挂载成一个磁盘。</p><h3 id="GPU-支持"><a href="#GPU-支持" class="headerlink" title="GPU 支持"></a>GPU 支持</h3><p><a href="https://zhuanlan.zhihu.com/p/149517344">https://zhuanlan.zhihu.com/p/149517344</a></p><h3 id="使用-Docker"><a href="#使用-Docker" class="headerlink" title="使用 Docker"></a>使用 Docker</h3><p>后续学习Docker时再补充……</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linux</tag>
      
      <tag>VS Code</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python开发环境搭建</title>
    <link href="/2019/10/28/Win10%E7%B3%BB%E7%BB%9F%E4%B8%8Bpython%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%EF%BC%88%E6%90%AD%E9%85%8DVsCode%E4%BD%BF%E7%94%A8%EF%BC%89/"/>
    <url>/2019/10/28/Win10%E7%B3%BB%E7%BB%9F%E4%B8%8Bpython%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%EF%BC%88%E6%90%AD%E9%85%8DVsCode%E4%BD%BF%E7%94%A8%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<h1 id="安装Python"><a href="#安装Python" class="headerlink" title="安装Python"></a>安装Python</h1><h2 id="下载并安装minicaonda"><a href="#下载并安装minicaonda" class="headerlink" title="下载并安装minicaonda"></a>下载并安装minicaonda</h2><p>conda是一个开源的软件包管理工具和环境管理系统，可以轻松创建虚拟环境，并在多个环境之间轻松切换。例如，我们可以分别创建Python3和Python2的独立软件环境，并在需要该环境时轻松进行切换（根据工作目录）。</p><p>与 conda有关的配置软件有两个，miniconda（含基本工具占用空间约400M），anaconda（包括常用到的python库以及GUI工具，占用空间约3G）。因为我们只是需要conda这个包管理工具，仅需要下载miniconda即可。</p><p>直接下载<a href="https://conda.io/miniconda.html">官方miniconda安装包</a>，在下载页面选择对应平台的安装包进行安装。 自带Python环境，可以根据自己长期使用的版本进行选择。下载好安装包后，安装时可以选择作为用户软件安装（储存到C盘下的<code>User/用户文件夹</code>），或者做为系统软件安装（所有用户都可以使用）</p><p>注意安装过程进行到到下面这一步时，需要勾选两个选项：添加miniconda至环境变量PATH，注册miniconda所带的python.exe为默认解释器</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/miniconda.png"></p><h2 id="安装第三方库的方法"><a href="#安装第三方库的方法" class="headerlink" title="安装第三方库的方法"></a>安装第三方库的方法</h2><ul><li>默认的conda源在国外，下载Python第三方包时由于大陆互联网的管制会很慢。因此我们可以使用清华的镜像，执行以下命令：</li></ul><pre><code class="hljs text">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/conda config --set show_channel_urls yes</code></pre><p>此时，在本地目录<code>C:\Users&lt;你的用户名&gt;</code>下就会生成配置文件<code>.condarc</code>，可以查看conda的所有源。</p><p>如果想要还原conda默认源，执行以下命令：</p><pre><code class="hljs python">conda config --remove-key channels</code></pre><ul><li>除了conda，Python还有一个自带的包管理工具pip，也可以将其替换为国内源，直接在user目录中创建一个pip目录，如：C:\Users\xxxx\pip，新建文件pip.ini，内容如下：</li></ul><pre><code class="hljs text">[global]index-url = https://pypi.tuna.tsinghua.edu.cn/simple</code></pre><ul><li>如果遇到在线下载一直失败（网速太慢），或者选择镜像源没有对应的包，可以尝试去以下两个网址下载离线文件进行解压：</li></ul><p><a href="https://repo.anaconda.com/pkgs/main/win-64/">https://repo.anaconda.com/pkgs/main/win-64/</a></p><p><a href="https://www.lfd.uci.edu/~gohlke/pythonlibs/#ecos">https://www.lfd.uci.edu/~gohlke/pythonlibs/#ecos</a></p><h2 id="虚拟环境的使用"><a href="#虚拟环境的使用" class="headerlink" title="虚拟环境的使用"></a>虚拟环境的使用</h2><p>虚拟环境的好处可以使我们在创建不同的Python项目时，避免相互之间的影响。</p><p>若我现在需要做一个项目使用 python3.6 的环境，可以在终端运行以下命令</p><pre><code class="hljs text">conda create --name 项目名 python=3.6</code></pre><p>创建环境的过程中会让你确认该环境所需软件包，一般直接输入y后按回车就可以了。环境创建在miniconda安装路径下的<code>\env</code>子文件夹下：</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/env_location.JPG"></p><p><a href="https://blog.csdn.net/lyy14011305/article/details/59500819">点此查看更多虚拟环境的使用方法</a></p><h1 id="VsCode配置"><a href="#VsCode配置" class="headerlink" title="VsCode配置"></a>VsCode配置</h1><p><strong>Win10下最为省事的还是Pycharm，不过Pycharm比较吃内存我还是喜欢用轻量化的Vscode，并且Vscode有丰富的插件支持</strong></p><p>在windows平台下，由于VsCode打开的终端默认支持的是powershell，单因为某些原因在powershell内输入激活conda所创建的虚拟环境命令，并不能成功生效</p><ul><li>一种解决办法是打开VsCode的terminal窗口，将默认的shell手动修改为cmd。重启之后终端输入<code>conda activate 虚拟环境名</code>激活所创建的虚拟环境</li></ul><p>输入<code>conda deactivate</code>退出虚拟环境。</p><ul><li>当然，如果熟悉在linux下工作的指令，可以尝试将Vscode的默认终端改成gitbash，gitbash可以通过下载git软件来获取。</li></ul><p>下载好git后打开VsCode的用户设置文件<code>ctrl+shifp+p</code>，修改<code>setting.json</code>文件增加如下两行：</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/modify_setting.JPG"></p><p>重启VsCode后终端默认调用的shell就变成了gitbash：</p><p>不过此时还需要一个步骤，在终端首先输入<code>source activate</code>，可以看到此时已经激活了conda，这是还是base环境即默认的Python解释器</p><p>终端输入<code>conda activate 虚拟环境名</code>激活所创建的虚拟环境</p><h1 id="Jupyterlab"><a href="#Jupyterlab" class="headerlink" title="Jupyterlab"></a>Jupyterlab</h1><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>Jupyter源于Ipython Notebook，是使用Python（也有R、Julia、Node等其他语言的内核）进行代码演示、数据分析、可视化、教学的很好的工具.</p><p>直接用conda安装，在命令行执行</p><pre><code class="hljs text">conda install -c conda-forge jupyterlab</code></pre><p>接着使用<code>jupyter-lab</code>或<code>jupyter lab</code>命令，然后默认浏览器会自动打开Jupyter Lab。</p><p>更多的操作详见：<a href="https://zhuanlan.zhihu.com/p/154515490">https://zhuanlan.zhihu.com/p/154515490</a></p><h2 id="指定kernel"><a href="#指定kernel" class="headerlink" title="指定kernel"></a>指定kernel</h2><p>为不同的项目指定python kernel，创建jupyterlab做分析：</p><pre><code class="hljs mipsasm">conda <span class="hljs-keyword">install </span>ipykernel<span class="hljs-comment"># 安装kernel</span>ipython kernel <span class="hljs-keyword">install </span>--user --name 虚拟环境名称<span class="hljs-comment"># 查看已安装kernel</span><span class="hljs-keyword">jupyter </span>kernelspec list<span class="hljs-comment"># 删除kernel</span><span class="hljs-keyword">jupyter </span>kernelspec remove 虚拟环境名称</code></pre><p>在默认浏览器打开Jupyter Lab的界面，选择：</p><p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/jupyterlab_env.png"></p><p>如果是要结合virtualenv创建的虚拟环境，参考<a href="https://blog.csdn.net/weixin_40539892/article/details/80940885">这篇文章</a></p><h2 id="插件安装"><a href="#插件安装" class="headerlink" title="插件安装"></a>插件安装</h2><p><a href="https://zhuanlan.zhihu.com/p/101070029">15个好用到爆炸的Jupyter Lab插件</a></p><h1 id="深度学习平台的配置"><a href="#深度学习平台的配置" class="headerlink" title="深度学习平台的配置"></a>深度学习平台的配置</h1><p>深度学习需要在电脑上进行GPU上的计算，比如运行TensorFlow或者Pytorch等，首先需要解决的是正确安装CUDA和CUDNN，下面介绍如何在Win10系统上完成以上操作：</p><h2 id="查看本机的CUDA驱动适配版本"><a href="#查看本机的CUDA驱动适配版本" class="headerlink" title="查看本机的CUDA驱动适配版本"></a>查看本机的CUDA驱动适配版本</h2><p>系统具有 NVIDIA 显卡，则往往已经自动安装了 NVIDIA 显卡驱动程序。如未安装，直接访问 <a href="https://www.nvidia.com/Download/index.aspx?lang=en-us">NVIDIA 官方网站</a> 下载并安装对应型号的最新公版驱动程序即可。</p><p>在桌面右键“NVIDIA控制面板”，点击帮助-&gt;系统信息-&gt;组件。（前提是你的电脑有英伟达的显卡）</p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/nvidia_control.png" style="zoom:80%;" /><p>在打开的窗口中，我们可以看到本机目前最高支持的CUDA版本。如果你升级了显卡驱动，将来也可能会支持更高版本。</p><h2 id="下载和安装CUDA和cuDNN"><a href="#下载和安装CUDA和cuDNN" class="headerlink" title="下载和安装CUDA和cuDNN"></a>下载和安装CUDA和cuDNN</h2><ul><li><p>CUDA下载页面：<a href="https://developer.nvidia.com/cuda-downloads">https://developer.nvidia.com/cuda-downloads</a></p><p>如果需要选择CUDA版本，可从这里打开：<a href="https://developer.nvidia.com/cuda-toolkit-archive">https://developer.nvidia.com/cuda-toolkit-archive</a></p><p>CUDA安装完成后打开命令行，执行<code>nvcc -V</code> ，成功的话会返回cuda版本号。</p><p>接下来需要在系统环境变量的Path项下添加几个路径，需要添加的默认的安装路径如下：</p><pre><code class="hljs text">C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\binC:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp</code></pre></li><li><p>下载cuDNN时必须选择和你安装的CUDA匹配的版本，下载页面：<a href="https://developer.nvidia.com/rdp/cudnn-download%E3%80%82%E4%B8%8B%E8%BD%BDcuDNN%E6%98%AF%E9%9C%80%E8%A6%81%E7%99%BB%E5%BD%95%E8%8B%B1%E4%BC%9F%E8%BE%BE%E5%BC%80%E5%8F%91%E8%80%85%E8%B4%A6%E6%88%B7%E7%9A%84%EF%BC%8C%E5%A6%82%E6%9E%9C%E6%B2%A1%E6%9C%89%E7%9A%84%E8%AF%9D%EF%BC%8C%E9%9C%80%E8%A6%81%E6%B3%A8%E5%86%8C%E4%B8%80%E4%B8%AA%E5%B9%B6%E5%A1%AB%E5%86%99%E9%97%AE%E5%8D%B7%EF%BC%8C%E5%BE%88%E7%AE%80%E5%8D%95%E3%80%82%E6%B3%A8%E5%86%8C%E5%B9%B6%E7%99%BB%E5%BD%95%E5%90%8E%EF%BC%8C%E5%8D%B3%E5%8F%AF%E6%89%93%E5%BC%80%E5%A6%82%E4%B8%8B%E9%A1%B5%E9%9D%A2%EF%BC%8C%E9%80%89%E6%8B%A9%E5%AF%B9%E5%BA%94%E7%9A%84%E6%96%87%E4%BB%B6%E5%B9%B6%E4%B8%8B%E8%BD%BD%E3%80%82">https://developer.nvidia.com/rdp/cudnn-download。下载cuDNN是需要登录英伟达开发者账户的，如果没有的话，需要注册一个并填写问卷，很简单。注册并登录后，即可打开如下页面，选择对应的文件并下载。</a></p><p>安装cuDNN首先需要解压cuDNN压缩包，可以看到有<code>bin、include、lib</code>目录。</p><p>打开 <code>“C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA”</code> 目录，找到你安装的版本目录，打开，将cuDNN压缩包内<code>bin、include、lib</code>目录下的文件分别复制过去。</p></li></ul><h2 id="Tensorflow"><a href="#Tensorflow" class="headerlink" title="Tensorflow"></a>Tensorflow</h2><p>安装tensorflow是基于Python的，所以我们先创建一个用于tensorflow开发的虚拟环境。</p><p>安装tenforflow需要注意各个依赖之间的版本适配，去官网可以查到对应关系：</p><p><a href="https://tensorflow.google.cn/install/source_windows#gpu">https://tensorflow.google.cn/install/source_windows#gpu</a></p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>VS Code</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hexo博客搭建指南</title>
    <link href="/2019/10/21/%E4%BD%BF%E7%94%A8Hexo-Github%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"/>
    <url>/2019/10/21/%E4%BD%BF%E7%94%A8Hexo-Github%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/</url>
    
    <content type="html"><![CDATA[<h1 id="Hexo简介"><a href="#Hexo简介" class="headerlink" title="Hexo简介"></a>Hexo简介</h1><p>Hexo是一款基于Node.js的静态博客框架，依赖少易于安装使用，可以方便的生成静态网页托管在GitHub上，是搭建博客的首选框架。更多详细信息可以进入<a href="https://link.zhihu.com/?target=https://hexo.io/zh-cn/">hexo官网</a>进行查看，Hexo的创建者是台湾人，对中文的支持很友好。</p><h1 id="安装准备"><a href="#安装准备" class="headerlink" title="安装准备"></a>安装准备</h1><h2 id="注册github账户"><a href="#注册github账户" class="headerlink" title="注册github账户"></a>注册github账户</h2><p>因为需要使用github page来托管我们的网站（当然后续也可以通过申请个人域名），因此首先你需要注册一个github账户，登录github网站按照网站提示的步骤进行操作。</p><h2 id="本地安装并配置git"><a href="#本地安装并配置git" class="headerlink" title="本地安装并配置git"></a>本地安装并配置git</h2><p>Git是目前世界上最先进的分布式版本控制系统，可以有效、高速的处理从很小到非常大的项目版本管理。也就是用来管理你的hexo博客文章，上传到GitHub的工具。Git非常强大，作为程序开发人员都应掌握git的使用。廖雪峰老师的<a href="https://link.zhihu.com/?target=https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000">Git教程</a>写的非常好</p><p>在git官网下载安装 git for windows，下载后会有一个git bash的命令行工具，以后就用这个工具来使用git，在git bash执行：</p><pre><code class="hljs text">git config --global user.name &quot;xiangli-bjtu&quot;  // 换成自己的github用户名，非昵称 git config --global user.email  &quot;xavierlee.gy@gmail.com&quot;  // 填写自己的github注册邮箱</code></pre><h2 id="配置ssh免密登录"><a href="#配置ssh免密登录" class="headerlink" title="配置ssh免密登录"></a>配置ssh免密登录</h2><p>提交代码需要提供你的github权限才可以，但是直接使用用户名和密码太不安全了，所以我们使用ssh key来解决本地和服务器的连接问题。右键git bash执行以下命令：</p><pre><code class="hljs text">ssh-keygen -t rsa -C &quot;xavierlee.gy@gmail.com&quot;</code></pre><p>然后连续3次回车，会在用户目录下生成一个<code>.ssh</code>文件夹里面有公钥、私钥、主机列表三个文件。打开<code>.ssh\id_rsa.pub</code>文件，这个就是公钥。然后进入你的github主页，进入<code>个人设置 → SSH and GPG keys → New SSH key</code>将刚复制的内容粘贴到key那里，title随便填，保存。</p><p>输入以下命令检查是否配置成功：</p><pre><code class="hljs text">ssh -T git@github.com</code></pre><p>出现提示，输入yes，如果之后看到<code>You&#39;ve successfully authenticated, but GitHub does not provide shell access.</code>说明SSH已配置成功！</p><p><a href="https://www.jianshu.com/p/33461b619d53">关于ssh的原理</a></p><h2 id="安装node-js"><a href="#安装node-js" class="headerlink" title="安装node.js"></a>安装node.js</h2><p>创建博客的hexo工具基于node.js，所以需要安装一下node.js和包管理工具npm，直接去官网下载安装即可。</p><p>检测npm是否安装成功，在命令行中输入<code>npm -v </code>。另外，windows在git安装完后，就可以直接使用git bash来敲命令行了，不用自带的cmd</p><p>由于默认的npm源在国外，需要更换npm源为淘宝源：</p><pre><code class="hljs text">npm config set registry https://registry.npm.taobao.org</code></pre><p>在用户目录下会生成一个<code>.npmrc</code>文件可以查看使用的源。</p><h1 id="Hexo博客搭建"><a href="#Hexo博客搭建" class="headerlink" title="Hexo博客搭建"></a>Hexo博客搭建</h1><h2 id="安装hexo和创建博客目录"><a href="#安装hexo和创建博客目录" class="headerlink" title="安装hexo和创建博客目录"></a>安装hexo和创建博客目录</h2><ol><li>hexo是一个基于node.js的工具，能将用于撰写博客的markdown文档渲染为网页。在电脑一个合适的位置创建一个文件夹，可以命名为blog，hexo框架与博客有关内容都在这个文件夹中，进入这个文件夹下直接右键git bash打开，输入以下命令安装hexo。</li></ol><pre><code class="hljs text">npm install -g hexo-cli</code></pre><p>接下来进行博客的初始化</p><pre><code class="hljs text">hexo init</code></pre><p>初始化完成之后，我们可以看到多个文件目录：</p><ul><li><code>node_modules</code>: 依赖包</li><li><code>public</code>：存放生成的页面</li><li><code>scaffolds</code>：生成文章的一些模板</li><li><code>source</code>：用来存放你的文章</li><li><code>themes</code>：主题</li><li><code>_config.yml</code>: 博客的配置文件</li></ul><p>执行</p><pre><code class="hljs text">hexo cleanhexo generate</code></pre><p>其中 <code>hexo clean</code>清除了你之前生成的东西，也可以不加，更为简略的命令是使用缩写用 <code>hexo c</code></p><p> <code>hexo generate</code> 顾名思义生成静态文章，可以用 <code>hexo g</code>缩写</p><p>将本地的markdown文件编译成静态文件（即显示网页必须的内容如html、css、js等）。这些内容会保存博客文件夹内。接下来执行<code>hexo s</code> 测试hexo是否安装成功，打开浏览器访问 <a href="http://localhost:4000/">http://localhost:4000</a> 若能看到内容则说明安装成功</p><p>使用<code>ctrl+c</code>可以把服务关掉。</p><h2 id="部署到github"><a href="#部署到github" class="headerlink" title="部署到github"></a>部署到github</h2><p>上面只是在本地生成了博客文件，接下来要做的就是就是把博客内容发布到github上，这样就可以让其他的人进行访问。我们需要安装插件，用来将本地hexo博客的内容部署到github</p><pre><code class="hljs text">npm install hexo-deployer-git --save</code></pre><p>在github创建一个名为<code>xiangli-bjtu.github.io</code>的远程仓库，如果你的github用户名是test，那么你就新建<code>test.github.io</code>的仓库（必须是你的用户名，这是固定要求其它名称无效），将来你的网站访问地址就是 <a href="http://test.github.io/">http://test.github.io</a> 了</p><p>接下来我们需要修改本地hexo博客目录的配置文件<code>_config.yml</code>中有关deploy的部分</p><pre><code class="hljs text">deploy:  type: git    repository: git@github.com:xiangli-bjtu/xiangli-bjtu.github.io.git  branch: main  # 2021年修改：由于美国弗洛伊德事件引发的BLM运动，github已将默认分支的名称由原来带有正义的master修改为main</code></pre><p>然后执行</p><pre><code class="hljs text">hexo cleanhexo generatehexo deploy</code></pre><p>就可以将本地public文件夹下的内容上传部署到github，过一会儿就可以在<code>xiangli-bjtu.github.io</code>这个网站看到你的博客了。</p><h1 id="Hexo配置"><a href="#Hexo配置" class="headerlink" title="Hexo配置"></a>Hexo配置</h1><p>在文件根目录下的<code>_config.yml</code>，就是整个hexo框架的配置文件了。可以在里面修改大部分的配置。详细可参考<a href="https://link.zhihu.com/?target=https://hexo.io/zh-cn/docs/configuration">官方的配置</a>描述。</p><p>下面介绍几个常用的配置：</p><h2 id="网站信息"><a href="#网站信息" class="headerlink" title="网站信息"></a><strong>网站</strong>信息</h2><p><code>title</code>：网站标题</p><p><code>subtitle</code>网站副标题</p><p><code>description</code>网站描述，主要用于SEO，告诉搜索引擎一个关于您站点的简单描述，通常建议在其中包含您网站的关键词。</p><p><code>author</code>您的名字</p><p><code>language</code>网站使用的语言</p><p><code>timezone</code>网站时区。Hexo 默认使用您电脑的时区。<a href="https://link.zhihu.com/?target=https://en.wikipedia.org/wiki/List_of_tz_database_time_zones">时区列表</a>。比如说：<code>America/New_York</code>, <code>Japan</code>, 和 <code>UTC</code> 。</p><h2 id="博客图片内容管理"><a href="#博客图片内容管理" class="headerlink" title="博客图片内容管理"></a>博客图片内容管理</h2><p>修改本地hexo博客目录下站点配置文件<code>_config.yml</code>中的<code>post_asset_folder:false</code>这个选项设置为<code>true</code>。这样在运行<code>hexo n &quot;xxxx&quot;</code>来生成marnkown文时，<code>/source/_posts</code>文件夹内除了xxxx.md文件还有一个同名的文件夹，用于存放markdown文件里需要插入的图片</p><h2 id="Front-matter"><a href="#Front-matter" class="headerlink" title="Front-matter"></a><strong>Front-matter</strong></h2><p> <a href="https://hexo.io/zh-cn/docs/front-matter">Front-matter</a>  是markdown文件最上方以 <code>---</code> 分隔的区域，用于指定个别文件的变量，举例来说：</p><pre><code class="hljs text">title: Hello Worlddate: 2013/7/13 20:46:25---</code></pre><p>下是预先定义的参数，您可在模板中使用这些参数值并加以利用。</p><p><code>layout</code> 布局</p><p><code>title </code>文章标题</p><p><code>date </code>建立日期</p><p><code>updated </code>更新日期</p><p><code>comments </code>开启文章的评论功能</p><p><code>tags </code>标签</p><p><code>categories </code>分类</p><p><code>permalink </code>覆盖文章网址</p><p>其中分类和标签的区别在于：分类具有顺序性和层次性，也就是说 <code>Foo, Bar</code> 不等于 <code>Bar, Foo</code>；而标签没有顺序和层次。</p><h2 id="3种layout（布局）"><a href="#3种layout（布局）" class="headerlink" title="3种layout（布局）"></a>3种<strong>layout（布局）</strong></h2><p>Hexo 有三种默认布局：<code>post</code>、<code>page</code> 和 <code>draft</code>。在创建这三种不同类型的文件时，它们将会被保存到不同的路径：</p><table><thead><tr><th align="left">布局</th><th align="left">路径</th></tr></thead><tbody><tr><td align="left"><code>post</code></td><td align="left"><code>source/_posts</code></td></tr><tr><td align="left"><code>page</code></td><td align="left"><code>source</code></td></tr><tr><td align="left"><code>draft</code></td><td align="left"><code>source/_drafts</code></td></tr></tbody></table><ul><li>默认的布局是<code>post</code>，当你每一次使用代码</li></ul><pre><code class="hljs text">hexo n</code></pre><p>它其实默认使用了<code>post</code>布局，也就是在<code>source</code>文件夹下的<code>_post</code>里面生成博客文件</p><ul><li>如果你想另起一页，那么可以使用<code>page</code>布局</li></ul><pre><code class="hljs text">hexo new page board</code></pre><p>系统会自动给你在source文件夹下创建一个board文件夹，以及board文件夹中的index.md，这样你访问的board对应的链接就是<code>http://xxx.xxx/board</code></p><ul><li><p><code>draft</code>是Hexo 的一种特殊布局，也就是你如果想写文章，又不希望发布时被看到，可以使用该布局。若在写草稿文件的过程中，想要预览一下，那么可以使用以下命令，在本地端口中开启服务预览。</p><pre><code class="hljs text">hexo server --draft</code></pre><p>如果想把草稿转为post，可通过 <code>publish</code> 命令将草稿移动到 <code>source/_posts</code> 文件夹，该命令的使用方式与 <code>new</code> 十分类似</p><pre><code class="hljs text">hexo publish draft newpage</code></pre><h2 id="更换Hexo主题"><a href="#更换Hexo主题" class="headerlink" title="更换Hexo主题"></a>更换Hexo主题</h2></li></ul><p>如果对原始的hexo主题不满意，hexo还提供了丰富的主题进行选择，这里我使用的是<a href="https://fluid-dev.github.io/hexo-fluid-docs/start/#%E6%90%AD%E5%BB%BA-hexo-%E5%8D%9A%E5%AE%A2">fluid主题</a>。这里仅介绍几个用到的主题配置步骤，更多的可以去看fluid主题的官网文档</p><h3 id="安装主题"><a href="#安装主题" class="headerlink" title="安装主题"></a><strong>安装主题</strong></h3><p>下载<a href="https://codeload.github.com/fluid-dev/hexo-theme-fluid/zip/v1.8.4">fluid</a>解压到 themes 目录，并将解压出的文件夹重命名为 <code>fluid</code>。</p><p>修改博客目录下的站点配置文件 <code>_config.yml</code></p><pre><code class="hljs text">theme: fluid</code></pre><h3 id="页面顶部大图"><a href="#页面顶部大图" class="headerlink" title="页面顶部大图"></a><strong>页面顶部大图</strong></h3><ul><li>图源</li></ul><p><strong>主题配置文件</strong>中，每个页面都有名为 <code>banner_img</code> 的属性，可以使用本地图片的相对路径，也可以为外站链接，比如：</p><p>指向本地图片：</p><pre><code class="hljs text">banner_img: /img/bg/example.jpg   # 对应存放在 /source/img/bg/example.jpg</code></pre><p>本地图片时可自定义路径，但必须在 source 目录下。图片大小建议压缩到 1MB 以内，否则会严重拖慢页面加载。</p><p>指向外站链接：</p><pre><code class="hljs text">banner_img: https://static.zkqiang.cn/example.jpg</code></pre><ul><li>高度</li></ul><p>鉴于每个人的喜好不同，开放对页面 <code>banner_img</code> 高度的控制。</p><p><strong>主题配置文件</strong>中，每个页面对应的 <code>banner_img_height</code> 属性，有效值为 0 - 100。100 即为全屏，个人建议 70 以上。</p><ul><li>蒙版透明度</li></ul><p><strong>主题配置文件</strong>中，每个页面对应的 <code>banner_mask_alpha</code> 属性，有效值为 0 - 1.0， 0 是完全透明（无蒙版），1 是完全不透明</p><h3 id="博客标题"><a href="#博客标题" class="headerlink" title="博客标题"></a><strong>博客标题</strong></h3><p>页面左上角的博客标题，默认使用<strong>博客配置</strong>中的 <code>title</code>，这个配置同时控制着网页在浏览器标签中的标题。</p><p>如需单独区别设置，可在<strong>主题配置</strong>中设置：</p><pre><code class="hljs text">navbar:  blog_title: 记录学习的点滴 # 导航栏左侧的标题，为空则按 hexo config.title 显示</code></pre><h3 id="文章在首页的略缩图"><a href="#文章在首页的略缩图" class="headerlink" title="文章在首页的略缩图"></a>文章在首页的略缩图</h3><p>markdown文章开头的 <code>Front-matter</code> ，可添加 <code>index_img</code> 属性。</p><pre><code class="hljs text">---title: 文章标题tags: [Hexo, Fluid]index_img: /img/example.jpgdate: 2019-10-10 10:00:00---文章内容</code></pre><p>和 Banner 配置相同，<code>/img/example.jpg</code> 对应的是存放在 <code>/source/img/example.jpg</code> 目录下的图片（目录也可自定义，但必须在 source 目录下）。也可以使用外链 Url 的绝对路径。</p><h3 id="创建「关于页」"><a href="#创建「关于页」" class="headerlink" title="创建「关于页」"></a>创建「关于页」</h3><p>在Fluid主题界面的菜单栏里，有一个about页面「关于页」，这个你现在点击进去时找不到网页的，因为你的文章中没有about这个东西。如果你想要的话，需要手动创建：</p><pre><code class="hljs text">hexo new page about</code></pre><p>它就会在根目录下<code>source</code>文件夹中新建了一个<code>about</code>文件夹，以及<code>index.md</code>。修改 <code>index.md</code>，为其添加 <code>layout</code> 属性，并在里面写s</p><p>修改后的文件示例如下：</p><pre><code class="hljs text">---title: aboutdate: 2019-10-21 21:23:01layout: about---这里写关于页的正文，支持 Markdown, HTML</code></pre><h3 id="支持Latex公式"><a href="#支持Latex公式" class="headerlink" title="支持Latex公式"></a>支持Latex公式</h3><p>当需要使用 Latex 语法的数学公式时，可手动开启本功能，需要完成三步操作：</p><p><strong>1. 设置主题配置</strong></p><pre><code class="hljs text">post:  math:    enable: true    specific: true    engine: mathjax</code></pre><p><code>specific</code>: 建议开启。当为 true 时，只有在文章 <code>Front-matter</code> 里指定 <code>math: true</code> 才会在文章页启动公式转换，以便在页面不包含公式时提高加载速度。</p><p><code>engine</code>: 公式渲染引擎，目前支持 <code>mathjax</code> 或 <code>katex</code>。</p><p><strong>MathJax</strong></p><p>优点</p><ul><li>对 LaTeX 语法支持全面</li><li>右键点击公式有扩展功能</li></ul><p>缺点</p><ul><li>需要加载 JS，页面加载会比较慢，并且有渲染变化</li><li>kramed 渲染器对内联公式的转义字符 <code>\</code> 支持不足</li></ul><p><strong>KaTeX</strong></p><p>优点</p><ul><li>没有 JS 不会影响页面加载</li><li>渲染器效果好 (相对 kramed 对 MathJax 的内联公式)</li></ul><p>缺点</p><ul><li>小部分 LaTeX 不支持</li></ul><p><strong>2. 更换 Markdown 渲染器</strong></p><p>由于 Hexo 默认的 Markdown 渲染器不支持复杂公式，所以必须更换渲染器。</p><p>先卸载原有渲染器：</p><pre><code class="hljs text">npm uninstall hexo-renderer-marked --save</code></pre><p>然后根据上方配置不同的 <code>engine</code>，推荐更换如下渲染器：</p><p>mathjax: <code>npm install hexo-renderer-kramed --save</code></p><p>katex: <code>npm install @upupming/hexo-renderer-markdown-it-plus --save</code></p><p><strong>3. 文章中设置</strong></p><p>如果你写的文章里面用到了数学公式，需要在文章Front-matter里打开mathjax开关。</p><pre><code class="hljs text">---title: index.htmldate: 2018-12-5 01:30:30tags:mathjax: true--</code></pre><h3 id="社交链接"><a href="#社交链接" class="headerlink" title="社交链接"></a>社交链接</h3><p>在主题配置中设置：</p><pre><code class="hljs yaml"><span class="hljs-attr">about:</span>  <span class="hljs-attr">icons:</span> <span class="hljs-comment"># 更多图标可从 https://hexo.fluid-dev.com/docs/icon/ 查找，class 代表图标的 css class</span>    <span class="hljs-bullet">-</span> &#123; <span class="hljs-attr">class:</span> <span class="hljs-string">&#x27;iconfont icon-github-fill&#x27;</span>, <span class="hljs-attr">link:</span> <span class="hljs-string">&#x27;https://github.com/xiangli-bjtu&#x27;</span>, <span class="hljs-attr">tip:</span> <span class="hljs-string">&#x27;GitHub&#x27;</span> &#125;    <span class="hljs-bullet">-</span> &#123; <span class="hljs-attr">class:</span> <span class="hljs-string">&#x27;iconfont icon-bilibili-fill&#x27;</span>, <span class="hljs-attr">link:</span> <span class="hljs-string">&#x27;https://space.bilibili.com/254950760&#x27;</span>, <span class="hljs-attr">tip:</span> <span class="hljs-string">&#x27;b站&#x27;</span> &#125;    <span class="hljs-bullet">-</span> &#123; <span class="hljs-attr">class:</span> <span class="hljs-string">&#x27;iconfont icon-zhihu-fill&#x27;</span>, <span class="hljs-attr">link:</span> <span class="hljs-string">&#x27;https://www.zhihu.com/people/li-xiang-43-89-60&#x27;</span>, <span class="hljs-attr">tip:</span> <span class="hljs-string">&#x27;知乎&#x27;</span> &#125;    <span class="hljs-bullet">-</span> &#123; <span class="hljs-attr">class:</span> <span class="hljs-string">&#x27;iconfont icon-wechat-fill&#x27;</span>, <span class="hljs-attr">qrcode:</span> <span class="hljs-string">&#x27;/img/wechat_QRcode.jpg&#x27;</span> &#125;</code></pre><ul><li><code>class</code>: 图标的 css class，主题内置图标详见<a href="https://fluid-dev.github.io/hexo-fluid-docs/icon/">这里</a></li><li><code>link</code>: 跳转链接</li><li><code>tip</code>: 鼠标悬浮在图标上显示的提示文字</li><li><code>qrcode</code>: 二维码图片，当使用此字段后，点击不再跳转，而是悬浮二维码（需要指定图片）</li></ul><h1 id="为博客开设图床"><a href="#为博客开设图床" class="headerlink" title="为博客开设图床"></a>为博客开设图床</h1><p>图床简单来说就是个图片仓库，随着我们写博客越来越多，若将博客内插入的图片全都存在本地会很占空间。</p><p>在各家厂商提供的图床服务中，GitHub 图床是个不错的选择，还支持 jsDelivr CDN 加速访问（jsDelivr 是一个免费开源的 CDN 解决方案），我们可以使用PicGo 工具一键上传图片，操作简单高效，GitHub 和 jsDelivr 都是大厂，不用担心跑路问题，不用担心速度和容量问题，而且完全免费，可以说是目前免费图床的最佳解决方案！</p><h3 id="创建Github图床仓库"><a href="#创建Github图床仓库" class="headerlink" title="创建Github图床仓库"></a>创建Github图床仓库</h3><p>首先我们创建仓库，命名为<code>Blog-images-hosting</code></p><h3 id="生成Token"><a href="#生成Token" class="headerlink" title="生成Token"></a>生成Token</h3><p>在主页依次选择【Settings】-【Developer settings】-【Personal access tokens】-【Generate new token】，填写好描述，勾选【repo】，然后点击【Generate token】生成一个Token，注意这个Token只会显示一次，自己先保存下来，或者等后面配置好PicGo后再关闭此网页</p><h3 id="配置PicGo"><a href="#配置PicGo" class="headerlink" title="配置PicGo"></a>配置PicGo</h3><p>PicGo是一个用于快速上传图片并获取图片 URL 链接的工具，前往<a href="https://github.com/Molunerfinn/picgo/releases">下载PicGo</a>，安装好后开始配置图床</p><ul><li><p>设定仓库名：按照【github用户名/图床仓库名】的格式填写</p></li><li><p>设定分支名：【main】</p></li><li><p>设定Token：粘贴之前生成的【Token】</p></li><li><p>指定存储路径：填写想要储存的路径，如【ITRHX-PIC/】，这样就会在仓库下创建一个名为 ITRHX-PIC 的文件夹，图片将会储存在此文件夹中</p></li><li><p>设定自定义域名：它的作用是在图片上传后生成访问链接，自定义域名需要按照这样去填写：</p><p><code>https://raw.githubusercontent.com/账户名/仓库名/main</code>，</p><p>比如我的是：<code>https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main</code></p></li></ul><h3 id="Typora集成PicGo"><a href="#Typora集成PicGo" class="headerlink" title="Typora集成PicGo"></a>Typora集成PicGo</h3><p>Hexo博客文档是markdown文件，推荐的一款编辑工具是Typora。点击<code>偏好设置 -&gt; 图像 -&gt;</code>，在上传服务，选择 PicGo(app)。PicGo路径，选择PicGo软件的安装路径。点击验证图片上传选项可以测试是否配置成功。</p><h1 id="实现在多终端上更新博客"><a href="#实现在多终端上更新博客" class="headerlink" title="实现在多终端上更新博客"></a>实现在多终端上更新博客</h1><p>hexo 是一个优秀的静态博客工具，唯一的不足就是源文件无法同步，让人几乎只能在一台电脑上写博客，为了解决这个问题，我们可以利用git的分支系统进行多终端工作了，这样每次打开不一样的电脑，只需要进行简单的配置和在github上把文件同步下来，就可以无缝操作了。</p><p>由于<code>hexo d</code>上传部署到github的其实是hexo编译后的文件（即博客目录下的public文件夹内容），是用来生成网页的，不包含源文件。</p><p>因此我们的思路就是利用git的分支管理，将源文件上传到github的另一个分支即可。</p><ul><li>首先在github仓库中新建一个分支<code>hexo-source</code>，用这个分支来存储博客的源文件，而<code>main</code>分支用来存放hexo编译后的网页文件。然后在这个仓库的settings中，选择默认分支为<code>hexo-source</code>（这样每次同步的时候就不用指定分支，比较方便）。</li><li>然后在本地的任意目录下，打开git bash，将默认分支克隆到本地</li></ul><pre><code class="hljs text">git clone git@github.com:xiangli-bjtu/xiangli-bjtu.github.io.git</code></pre><ul><li><p>将上述克隆到本地的仓库中，除了.git 文件夹外的所有文件都删掉</p><p>把之前我们写的博客源文件全部复制过来，除了<code>.deploy_git</code>。这里应该说一句，复制过来的源文件应该有一个<code>.gitignore</code>，用来忽略一些不需要的文件，如果没有的话，自己新建一个，在里面写上如下，表示这些类型文件不需要git：</p><pre><code class="hljs text">.DS_StoreThumbs.dbdb.json*.lognode_modules/public/.deploy*/</code></pre></li><li><p>然后</p></li></ul><pre><code class="hljs text">git add .# 将hexo源文件映射到远程repo上git commit -m &#x27;commit source files&#x27;# 将源文件push到分支git push</code></pre><p>然后就可以在github上看到新建了分支，里面已经有博客的源文件了。</p><p>这样，我们在<code>source</code>文件夹中写好一篇markdown文件后，博客的部署分为两步：</p><ol><li>当添加新文章或更改配置后，需要将hexo源文件push到分支<code>hexo-source</code>进行备份</li></ol><pre><code class="hljs text">git add .  //添加修改内容到本地仓储git commit -m &#x27;modify blog&#x27;  //提交修改内容到本地仓库git push  //将本地分支和分支下的内容推送到远程</code></pre><ol start="2"><li>接下来执行博客编译将网页静态文件上传:</li></ol><pre><code class="hljs text">hexo chexo d -g</code></pre><h2 id="更换设备后迁移博客"><a href="#更换设备后迁移博客" class="headerlink" title="更换设备后迁移博客"></a>更换设备后迁移博客</h2><p>如果我们换了一台电脑，配置好 Hexo 的环境，<a href="https://hsiaovv.github.io/2017/04/06/GitHub%E9%85%8D%E7%BD%AESSH-key/">配置 Git SSH key</a>，把博客源文件代码克隆下来:</p><pre><code class="hljs crmsh">git <span class="hljs-keyword">clone</span> <span class="hljs-title">xxxxxxxxx</span>.xx (你的 github page 的 repo 地址)</code></pre><p>博客源文件下载下来之后，默认的分支是 master，需要切换到 <code>blogSource</code> 分支</p><pre><code class="hljs maxima">git checkout <span class="hljs-built_in">origin</span>/blogSource</code></pre><p>然后cd到博客目录依次执行以下命令：</p><pre><code class="hljs cmake">npm <span class="hljs-keyword">install</span> hexonpm <span class="hljs-keyword">install</span>npm <span class="hljs-keyword">install</span> hexo-deployer-git --save</code></pre><p>接下来就可以开始愉快的写博客了，写完之后记得把源文件代码 push 到 Github 上，然后用 Hexo 部署到自己博客上面</p><h1 id="绑定域名"><a href="#绑定域名" class="headerlink" title="绑定域名"></a>绑定域名</h1><p><a href="https://blog.csdn.net/qq_29232943/article/details/52786603">https://blog.csdn.net/qq_29232943/article/details/52786603</a></p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Hexo</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
