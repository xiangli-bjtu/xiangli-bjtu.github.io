

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=&#34;auto&#34;>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="Xiang Li">
  <meta name="keywords" content="">
  <title>David Silver 强化学习教程（3）：动态规划 - 李翔的个人博客</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/github-gist.min.css" />
    
  

  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.3.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>记录学习的点滴</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" href="javascript:">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner intro-2" id="background" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container page-header text-center fade-in-up">
            <span class="h2" id="subtitle">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2020-05-28 22:20" pubdate>
        2020年5月28日 晚上
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      2.7k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      28
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto" id="post">
            <!-- SEO header -->
            <h1 style="display: none">David Silver 强化学习教程（3）：动态规划</h1>
            
            <div class="markdown-body" id="post-body">
              <p>从广义上讲，强化学习是序贯决策问题。在上一节，我们已经将强化学习纳入到马尔科夫决策过程MDP的框架之内，根据是否建立了环境模型（即状态转移概率），可以分为<strong>基于模型的动态规划方法和基于无模型的强化学习方法</strong>。</p>
<p>DP算法在增强学习领域应用十分有限，因为它们不仅要求理想的环境模型，同时在状态多的情况下导致计算量也非常大，但是在理论方面依然非常重要。 DP算法为本书后面章节的理解提供了必要的基础，强化学习所有的方法都可以看成是为了实现和DP相似的效果，只是弱化已知精确环境模型的假设。</p>
<h1 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h1><p>动态规划算法是解决复杂问题的一个方法，算法通过把复杂问题分解为子问题，通过求解子问题进而得到整个问题的解。在解决子问题的时候，其结果通常需要存储起来被用来解决后续复杂问题。当问题具有下列特性时，通常可以考虑使用动态规划来求解：</p>
<ul>
<li>最优子结构(Optimal substructure)：意味着我们的问题可以拆分成一个个的小问题，通过解决这个小问题，最后，我们能够通过组合小问题的答案，得到大问题的答案</li>
<li>重叠子问题(Overlapping subproblems)：子问题在复杂问题内重复出现，使得子问题的解可以被存储起来重复利用。</li>
</ul>
<p>马尔科夫决定过程（MDP）满足上述的两个属性，可以使用动态规划来求解MDP</p>
<ul>
<li>Bellman方程把问题递归为求解子问题，</li>
<li>价值函数就相当于存储了一些子问题的解，可以复用。</li>
</ul>
<p><strong>动态规划求解MDP</strong></p>
<p>使用动态规划解决MDP问题时，通常假设环境是有限马尔可夫决策过程。也就是说，我们假设环境的状态，动作，和奖励集合有限，且给出了他们的动态特性即转移概率</p>
<ul>
<li>动态规划应用于MDP的<strong>规划问题(planning)**而不是学习问题(learning)，我们必须</strong>对环境是完全已知的(Model-Based)**，才能做动态规划</li>
<li>动态规划对于prediction（评估策略）和control问题（找到最优策略可分为策略迭代和价值迭代）均能求解（定义请看第一章）</li>
</ul>
<p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course3.1.JPG" srcset="/img/loading.gif"></p>
<h1 id="策略评估求解预测问题"><a href="#策略评估求解预测问题" class="headerlink" title="策略评估求解预测问题"></a>策略评估求解预测问题</h1><p>首先要介绍的是策略评估，<strong>策略评估就是给定任意策略 $\pi$怎么判断该策略到底有多好即计算其状态值函数</strong>。这个评价由基于当前策略的值函数 $v_{\pi}(s)$衡量。下面是整个流程：</p>
<p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course3.2.JPG" srcset="/img/loading.gif"></p>
<ol>
<li><p>给定要评估的策略 $\pi$ 和MDP中所有状态的 value function $v_1$，一般是全部置为0。这个初始化不会影响迭代结果，并且它不会影响收敛速率。</p>
</li>
<li><p>如果要获得状态 $s$ 的价值函数，需要看在该状态下通过策略 $\pi$ 其状态能转移到了哪些后续状态式 $s^{‘}$ ；而在具体要计算的时候，利用第 $k$ 步迭代得到的这些后续状态 $s^{‘}$ 的价值函数，带入Bellman Expectation Equation，得到新一轮 $k+1$ 步迭代的价值函数</p>
<p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course3.3.JPG" srcset="/img/loading.gif"></p>
</li>
<li><p>反复第2步一直到价值函数值恒定不变，这个迭代过程的结果 $v_{\pi}$ 就是对当前策略的评估</p>
</li>
</ol>
<p><strong>示例：Evaluating a Random Policy in the Small Gridworld</strong></p>
<p>在这节课程中用到的例子是一个最快达到网格中的灰色点，我们从最开始的随机策略开始，对其进行策略评估</p>
<p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course3.4.JPG" srcset="/img/loading.gif"></p>
<ul>
<li>状态空间 S：图中灰色方格所示两个位置为终止状态</li>
<li>行为空间 A：{n, e, s, w} 对于任何非终止状态可以有向北、东、南、西移动四个行为</li>
<li>转移概率 P：任何试图离开方格世界的动作其位置将不会发生改变，其余条件下将100%地转移到动作指向的状态（即在边界格子时，任何试图冲出边界的行为都会维持在原地，其他情况下移动不会出现打滑走对角线的可能）</li>
<li>即时奖励 R：任何在非终止状态间的转移得到的即时奖励均为-1，进入终止状态即时奖励为0</li>
<li>衰减系数 $\gamma$：1</li>
<li>初始化为随机策略，对于任何非终止状态可以等概率朝4个方向移动，目标是最快达到灰色格子的状态</li>
</ul>
<p>迭代过程的详细步骤可以参考知乎叶强大佬的文章： <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/28084990">迭代法评估4*4方格世界下的随机策略</a></p>
<center><img src="https://pic3.zhimg.com/v2-0082e5876e2ea59bdcedc7912bb15a3a_b.jpg" srcset="/img/loading.gif" style="zoom: 90%;" /></center>

<p>可以看到，动态规划的策略评估计算过程并不复杂，但是如果我们的问题是一个非常复杂的模型的话，这个计算量还是非常大的。</p>
<blockquote>
<p>除了通过迭代进行策略评估外，这个视频还提到了解析解的方法，感兴趣的可以参考<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1nV411k7ve?p=3">https://www.bilibili.com/video/BV1nV411k7ve?p=3</a></p>
</blockquote>
<h1 id="策略迭代求解控制问题"><a href="#策略迭代求解控制问题" class="headerlink" title="策略迭代求解控制问题"></a>策略迭代求解控制问题</h1><p>现在我们正式介绍最优策略的解法之一，<strong>Policy Iteration策略迭代</strong>，它包括上面介绍的策略评估（policy evaluation）和策略改进（policy improvement）两个步骤。</p>
<p>现在我们已经通过策略评估确定了一个确定性策略$\pi$的状态价值函数，那么接下来的问题就是：是否可以找到一个更好的策略$\pi^{‘}$。最直接的办法就是对$\pi^{‘}$也进行策略评估得到状态价值函数，但这本身是个很耗时的工作。</p>
<p>下面要介绍的策略改进定理提供了更加简洁的思路：我们无需对新的策略$\pi^{‘}$直接求价值函数，而是考虑在状态 $s$下强制执行动作 $a=\pi^{‘}(s)$（注意在当前策略$\pi$下并不一定会采取这个动作$a$），然后遵从现有的策略$\pi$并计算出若$q{\pi}(s,\pi^{‘}(s))$的值。若相比于$V_{\pi}(s)$更大，新的策略事实上总体来说也会比较好。</p>
<p>我们一般采取贪婪策略提升的方法，即新的确定性策略 $\pi^{‘}$是根据当前状态$s$下所有动作中，贪婪地选使得后继状态价值增加最多的行为（即利用评估得到的$V_{\pi}(s)$求出$q{\pi}(s,\pi(s))$并从中选出最大的一项更新策略）</p>
<p>下面图展示Policy Iteration的过程：</p>
<p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course3.8.JPG" srcset="/img/loading.gif"></p>
<p>现在我们从理论的角度，来给出Policy Iteration一定会收敛到最优值函数和策略的证明：</p>
<ul>
<li>采取贪婪策略提升的方法得到新的策略</li>
</ul>
<p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course3.9.JPG" srcset="/img/loading.gif"></p>
<ul>
<li>在新的策略 $\pi^{‘}$ 下，可以得到下述的不等式关系</li>
</ul>
<p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course3.10.JPG" srcset="/img/loading.gif"></p>
<p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course3.11.JPG" srcset="/img/loading.gif"></p>
<ul>
<li>当policy improvement 停止的时候，上述的不等式关系变成全等式。此时也意味着bellman optimal Equation 被满足。找到了最优的策略</li>
</ul>
<p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course3.12.JPG" srcset="/img/loading.gif"></p>
<p>在small gridworld的例子中结合贪婪策略提升的方法，可以看出策略的不断提升</p>
<p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course3.5.JPG" srcset="/img/loading.gif"></p>
<p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course3.6.JPG" srcset="/img/loading.gif"></p>
<p>很多时候，<strong>策略的更新较早就收敛至最优策略，而状态价值的收敛要慢很多</strong>，是否有必要一定要迭代计算直到状态价值得到收敛呢？</p>
<p>从上面方格的例子中，我们可以看出来$k=3$的时候，策略已经达到最优，虽然此时还没有满足Bellman Optimal Equation的条件，但是最优的policy已经出来了。所以，在这之后我们做的一次次迭代实际上是无用功，Modified Policy Iteration希望解决的就是砍掉这些无用的迭代的过程，我们有以下解决方案：</p>
<ul>
<li>引入变量 $\epsilon $ 作为停止条件，在精度允许范围内即可结束</li>
<li>设定一个固定的策略评估次数$k$，策略评估在$k$次迭代之后就截至。事实上当$k=1$的时候，Policy Iteration算法就变成了接下来介绍的Value Iteration</li>
</ul>
<h1 id="价值迭代求解控制问题"><a href="#价值迭代求解控制问题" class="headerlink" title="价值迭代求解控制问题"></a>价值迭代求解控制问题</h1><p>策略迭代存在一个问题，就在于<strong>策略迭代每次迭代都需要进行策略评估，主要时间都花费在策略评估上，而策略评估本身可能需要多次迭代才能收敛</strong>，对一个简单的问题来说，在策略评估上花费的时间不算长；但对复杂的问题来说，这个步骤的时间实在有些长。那么是否可以提前结束策略评估呢？这就引出了下面要介绍的价值迭代。</p>
<p><strong>最优策略原则</strong></p>
<p>一个最优的策略，我们可以从两步来思考：</p>
<ul>
<li>从状态 $s$ 到下一个状态 $s^{‘}$，采取了最优的动作</li>
<li>后继状态每一步都按照最优的policy去做，那么我最后的结果就是最优的</li>
</ul>
<p>一个策略能够使得状态s获得最优价值，当且仅当：<strong>对于从状态s可以到达的任何状态s’，该策略能够使得状态s’的价值是最优价值：</strong></p>
<p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course3.13.JPG" srcset="/img/loading.gif"></p>
<p>我们可以知道我们期望的最终（goal）状态的位置以及反推需要明确的状态间关系，认为它是一个确定性的价值迭代<strong>。</strong>因此，我们可以把问题分解成一些列的子问题，<strong>从最终目标状态开始分析，逐渐往回推，直至推至所有状态。</strong></p>
<p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course3.14.JPG" srcset="/img/loading.gif"></p>
<p><strong>价值迭代流程</strong></p>
<p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course3.16.JPG" srcset="/img/loading.gif"></p>
<p>有关策略迭代和价值迭代的对比：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/26699028">策略迭代和价值迭代</a></p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>我们将这节课学到的一种Prediction方法和两种Control的方法信息总结一下：</p>
<p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course3.17.JPG" srcset="/img/loading.gif"></p>
<p>上图中时间复杂度的分析，$m$为可选动作，$n$为MDP中的可能状态。</p>
<p>进一步我们对比下价值迭代和策略迭代，这里借用Stackoverflow的一张图：</p>
<p><img src="https://raw.githubusercontent.com/xiangli-bjtu/Blog-images-hosting/main/img/david_course3.18.JPG" srcset="/img/loading.gif"></p>
<p>DP方法的一个特点是：所有的更新都依赖其后继状态的估计值，这称为<strong>自举（bootstrapping）</strong>。另一个特点就是开篇提到的需要精确知道环境模型。</p>
<p>对于非常大的问题，DP可能不实用，但与其他解决MDP的方法相比，DP方法实际上非常有效。在接下来的两节笔记中，会介绍<strong>不需要模型也不需要自举的方法——蒙特卡洛法；不需要模型但是需要自举的方法——时间差分法</strong>。</p>
<h1 id="补充内容：异步动态规划算法"><a href="#补充内容：异步动态规划算法" class="headerlink" title="补充内容：异步动态规划算法"></a>补充内容：异步动态规划算法</h1><p>参考<a target="_blank" rel="noopener" href="https://www.cnblogs.com/pinard/p/9463815.html">刘建平的博客</a></p>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/%E6%8A%80%E6%9C%AF/">技术</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/Reinforcement-Learning/">Reinforcement Learning</a>
                    
                      <a class="hover-with-bg" href="/tags/AI/">AI</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2020/06/02/David%20Silver%20%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%95%99%E7%A8%8B%EF%BC%884%EF%BC%89%EF%BC%9A%E5%85%8D%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%A2%84%E6%B5%8B/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">David Silver 强化学习教程（4）：免模型的预测</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2020/05/15/David%20Silver%20%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%95%99%E7%A8%8B%EF%BC%882%EF%BC%89%EF%BC%9A%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B/">
                        <span class="hidden-mobile">David Silver 强化学习教程（2）：马尔可夫决策过程</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  

  

  
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/main.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  



  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>







  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: '#post-body',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "David Silver 强化学习教程（3）：动态规划&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.staticfile.org/mathjax/3.0.5/es5/tex-svg.js" ></script>

  











</body>
</html>
